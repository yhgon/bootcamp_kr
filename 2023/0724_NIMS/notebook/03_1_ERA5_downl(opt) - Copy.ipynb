{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d64fcd1-4121-431e-bff1-7b4713164757",
   "metadata": {},
   "source": [
    "# NIMS-KISTI-NVIDIA Hackathon \n",
    "\n",
    "# Problem Statement \n",
    "\n",
    "\n",
    "\n",
    "## Agenda \n",
    " - Introduction to FourCastNet\n",
    " - Configure FourCastNet\n",
    " - Typoon Dataset (JMA best track) \n",
    " - ECMWF ERA5 dataset(CDS API)\n",
    " - custom interval \n",
    " - inference \n",
    " - post processing \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb50dbfe-bf18-4d07-931a-97642063f4f5",
   "metadata": {},
   "source": [
    "## download dataset with CDS API \n",
    "\n",
    "FourCastNet modeled variables\n",
    "<table align=\"left\" border=\"1\">\n",
    "  <tr>\n",
    "    <th>Vertical Level</th>\n",
    "    <th>Variable</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Surface</td>\n",
    "    <td>U10, V10, T2M, SP, MSLP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1000 hPa</td>\n",
    "    <td>U, V, Z</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>850 hPa</td>\n",
    "    <td>T, U, V, Z, RH</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>500 hPa</td>\n",
    "    <td>T, U, V, Z, RH</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>50 hPa</td>\n",
    "    <td>Z</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Integrated</td>\n",
    "    <td>TCWV</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "751be69f-ca25-4fa5-bd43-918117c17f12",
   "metadata": {},
   "source": [
    "# [register copernicus site ](https://cds.climate.copernicus.eu/user/login)\n",
    "\n",
    "copernicus support CDSAPI to download netcdf /grib2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39730a39-dc5e-4f4d-a376-d73f50ca39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyungon Ryu's key. \n",
    "#%%file ~/.cdsapirc\n",
    "#url: https://cds.climate.copernicus.eu/api/v2\n",
    "#key: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1adc974d-e69f-465f-9df9-20abec780afd",
   "metadata": {},
   "source": [
    "## manual download script CDS API\n",
    "- input : typoon list ( start, end date info)\n",
    "```\n",
    "typhoon_list = [\n",
    "{'id': '2221', 'dur': 15, 'start': '2022101700', 'end': '2022102012', 'latitude': 27.0, 'longitude': 156.4, 'lp': 1004, 'hws': 35, 'grade': 3},\n",
    "{'id': '2222', 'dur': 33, 'start': '2022102600', 'end': '2022110300', 'latitude': 10.1, 'longitude': 134.9, 'lp': 975, 'hws': 60, 'grade': 4},\n",
    "    # Add more typhoon data here...\n",
    "]\n",
    "```\n",
    "- tasks : download ECWMF ERA5 dataset for FourCastNet ( sl, pl, variables) \n",
    "| Vertical Level | Variable                |\n",
    "|:-------------- |:-----------------------|\n",
    "| Surface        | U10, V10, T2M, SP, MSLP |\n",
    "| 1000 hPa       | U, V, Z                |\n",
    "| 850 hPa        | T, U, V, Z, RH         |\n",
    "| 500 hPa        | T, U, V, Z, RH         |\n",
    "| 50 hPa         | Z                      |\n",
    "| Integrated     | TCWV                   |\n",
    " \n",
    "\n",
    "\n",
    "- Controlled during the span of two months, spanning the end of one month and the beginning of the next, when a typhoon occurs.\n",
    "example cases : \n",
    "```\n",
    "typhoon_list = [\n",
    "{'id': '8002', 'dur': 58, 'start': '1980053018', 'end': '1980060100', 'latitude': 8.3, 'longitude': 142.8, 'lp': 960, 'hws': 85, 'grade': 5},\n",
    "\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e40bd7-f545-4486-9ffa-0f6e77cadd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import os\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "\n",
    "PL_VARIABLES = ['geopotential', 'relative_humidity', 'temperature', 'u_component_of_wind', 'v_component_of_wind']\n",
    "SL_VARIABLES = ['10m_u_component_of_wind', '10m_v_component_of_wind', '2m_temperature', 'mean_sea_level_pressure', 'surface_pressure', 'total_column_water_vapour']\n",
    "\n",
    "\n",
    "def generate_pl_script(start_date, end_date, filename_prefix, save_dir):\n",
    "    save_path = os.path.join(save_dir, f\"{filename_prefix}_pl.nc\")\n",
    "    variables = ', '.join([f\"'{var}'\" for var in PL_VARIABLES])\n",
    "    script = f\"\"\"\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-pressure-levels',\n",
    "    {{\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': [{variables}],\n",
    "        'pressure_level': ['50', '500', '850', '1000'],\n",
    "        'year': ['{start_date[:4]}'],\n",
    "        'month': ['{start_date[4:6]}'],\n",
    "        'day': {list(range(int(start_date[6:8]), int(end_date[6:8]) + 1))},\n",
    "        'time': ['00:00', '06:00', '12:00', '18:00'],\n",
    "    }},\n",
    "    '{save_path}')\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "\n",
    "def generate_sl_script(start_date, end_date, filename_prefix, save_dir):\n",
    "    save_path = os.path.join(save_dir, f\"{filename_prefix}_sl.nc\")\n",
    "    variables = ', '.join([f\"'{var}'\" for var in SL_VARIABLES])\n",
    "    script = f\"\"\"\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {{\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'netcdf',\n",
    "        'variable': [{variables}],\n",
    "        'year': ['{start_date[:4]}'],\n",
    "        'month': ['{start_date[4:6]}'],\n",
    "        'day': {list(range(int(start_date[6:8]), int(end_date[6:8]) + 1))},\n",
    "        'time': ['00:00', '06:00', '12:00', '18:00'],\n",
    "    }},\n",
    "    '{save_path}')\n",
    "\"\"\"\n",
    "    return script\n",
    "\n",
    "\n",
    "def prepare_ERA5_typhoon_dataset(typhoon_list, debug=False, download=False, save_dir='./', custom_interval=None):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    for typhoon in typhoon_list:\n",
    "        typhoon_id = typhoon['id']\n",
    "        start_date = typhoon['start']\n",
    "        end_date = typhoon['end']\n",
    "        filename_prefix = f\"{typhoon_id}_{start_date}_{end_date}\"\n",
    "\n",
    "        if debug:\n",
    "            print(f\"DEBUG : IDX : {typhoon_id} Date : start:{start_date} end:{end_date}\")\n",
    "\n",
    "        if start_date[:6] == end_date[:6]:  # Single month case\n",
    "            pl_script = generate_pl_script(start_date, end_date, filename_prefix, save_dir)\n",
    "            sl_script = generate_sl_script(start_date, end_date, filename_prefix, save_dir)\n",
    "\n",
    "            if debug:\n",
    "                print(\"PL Script:\")\n",
    "                print(pl_script)\n",
    "                print(\"SL Script:\")\n",
    "                print(sl_script)\n",
    "\n",
    "            if download:\n",
    "                exec(pl_script)\n",
    "                exec(sl_script)\n",
    "        else:  # Dual month case\n",
    "            pl_script_first_month = generate_pl_script(start_date, start_date[:6] + '31', filename_prefix + '_first_month', save_dir)\n",
    "            sl_script_first_month = generate_sl_script(start_date, start_date[:6] + '31', filename_prefix + '_first_month', save_dir)\n",
    "\n",
    "            # Convert start date to a datetime object\n",
    "            start_date_dt = datetime.datetime.strptime(start_date, \"%Y%m%d%H\")\n",
    "\n",
    "            # Add one month to start date\n",
    "            start_date_next_month = start_date_dt.replace(month=start_date_dt.month % 12 + 1, day=1)\n",
    "\n",
    "            # Format as string in the same format as the original dates\n",
    "            start_date_next_month_str = start_date_next_month.strftime(\"%Y%m%d%H\")\n",
    "\n",
    "            pl_script_second_month = generate_pl_script(start_date_next_month_str, end_date, filename_prefix + '_second_month', save_dir)\n",
    "            sl_script_second_month = generate_sl_script(start_date_next_month_str, end_date, filename_prefix + '_second_month', save_dir)\n",
    "\n",
    "            if debug:\n",
    "                print(\"PL Script (First Month):\")\n",
    "                print(pl_script_first_month)\n",
    "                print(\"SL Script (First Month):\")\n",
    "                print(sl_script_first_month)\n",
    "                print(\"PL Script (Second Month):\")\n",
    "                print(pl_script_second_month)\n",
    "                print(\"SL Script (Second Month):\")\n",
    "                print(sl_script_second_month)\n",
    "\n",
    "            if download:\n",
    "                exec(pl_script_first_month)\n",
    "                exec(sl_script_first_month)\n",
    "                exec(pl_script_second_month)\n",
    "                exec(sl_script_second_month)\n",
    "\n",
    "                merge_netcdf_files(filename_prefix, [f\"{filename_prefix}_first_month_pl.nc\", f\"{filename_prefix}_second_month_pl.nc\"], f\"{filename_prefix}_pl.nc\", save_dir)\n",
    "                merge_netcdf_files(filename_prefix, [f\"{filename_prefix}_first_month_sl.nc\", f\"{filename_prefix}_second_month_sl.nc\"], f\"{filename_prefix}_sl.nc\", save_dir)\n",
    "\n",
    "\n",
    "def merge_netcdf_files(output_filename, input_filenames, merged_filename, save_dir='./'):\n",
    "    merged_path = os.path.join(save_dir, merged_filename)\n",
    "    input_paths = [os.path.join(save_dir, filename) for filename in input_filenames]\n",
    "    datasets = [xr.open_dataset(path) for path in input_paths]\n",
    "    merged_dataset = xr.concat(datasets, dim='time')\n",
    "    merged_dataset.to_netcdf(merged_path)\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for path in input_paths:\n",
    "        os.remove(path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9af016d0-8c03-4dbe-8b9b-4631c5bda47f",
   "metadata": {},
   "source": [
    "### download dataset  (debug mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e156c8-74b9-4ba3-b934-3db8e6a3bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "typhoon_list = [\n",
    "    {'id': '8002', 'dur': 58, 'start': '1980053018', 'end': '1980060100', 'latitude': 8.3, 'longitude': 142.8, 'lp': 960, 'hws': 85, 'grade': 5},\n",
    "    # Add more typhoon data here...\n",
    "]\n",
    "\n",
    "# Run in debug mode\n",
    "prepare_ERA5_typhoon_dataset(typhoon_list, debug=True, download=False, save_dir='custom_interval')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6a68c74-1b0b-49f8-b883-54525c468c01",
   "metadata": {},
   "source": [
    "### download dataset  (actual download mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c7007-c3e3-4ac7-bbb8-a7a60f25ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "typhoon_list = [\n",
    "    {'id': '2211', 'dur': 69, 'start': '2022082718', 'end': '2022090900', 'latitude': 23.8, 'longitude': 151.1, 'lp': 920, 'hws': 105, 'grade': 5}, # HINNAMNO\n",
    "    #{'id': '2214', 'dur': 47, 'start': '2022091212', 'end': '2022092000', 'latitude': 22.3, 'longitude': 138.7, 'lp': 910, 'hws': 105, 'grade': 5},  # NANMADOL\n",
    "    # {'id': '1825', 'dur': 49, 'start': '2018092800', 'end': '2018100712', 'latitude': 7.4, 'longitude': 150.9, 'lp': 900, 'hws': 115, 'grade': 5}, # kong-rey\n",
    "    # {'id': '1826', 'dur': 54, 'start': '2018102018', 'end': '2018110300', 'latitude': 8.4, 'longitude': 160.7, 'lp': 900, 'hws': 115, 'grade': 5}, # yutu\n",
    "    # Add more typhoon data here...\n",
    "]\n",
    "\n",
    "# Run in debug mode\n",
    "prepare_ERA5_typhoon_dataset(typhoon_list, debug=True, download=True, save_dir='custom_interval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2252d52-e315-4281-a590-0aa54d8dd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah custom_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb329a-89e3-453b-9086-b0af01e731a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
