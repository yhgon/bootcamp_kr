{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d64fcd1-4121-431e-bff1-7b4713164757",
   "metadata": {},
   "source": [
    "# NIMS-KISTI-NVIDIA Hackathon \n",
    "\n",
    "# Problem Statement \n",
    "\n",
    "\n",
    "\n",
    "## Agenda \n",
    " - Introduction to FourCastNet\n",
    " - Configure FourCastNet\n",
    " - Typoon Dataset (JMA best track) \n",
    " - ECMWF ERA5 dataset(CDS API)\n",
    " - custom interval \n",
    " - inference \n",
    " - post processing \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e424b-8735-432f-b4e8-f5f8213ea644",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction to FourCastNet\n",
    "\n",
    " - [FourCastNet Paper Link](https://arxiv.org/abs/2202.11214)\n",
    " - [GitHub Repository](https://github.com/NVlabs/FourCastNet)\n",
    " \n",
    "FourCastNet, short for Fourier ForeCasting Neural Network, is a global data-driven weather forecasting model that provides accurate short to medium range global predictions at 0.25° resolution.\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src=\"https://github.com/NVlabs/FourCastNet/blob/master/assets/FourCastNet.gif?raw=true\">\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebfcdf-dd00-467e-8bfd-f81b5c64f649",
   "metadata": {},
   "source": [
    "\n",
    "### FourCastNet Architecture :\n",
    "FourCastNet uses a Fourier transform-based token-mixing scheme with a vision transformer (ViT) backbone. This approach is based on the recent Fourier neural operator that learns in a resolution-invariant manner and has shown success in modeling challenging partial differential equations (PDE) such as fluid dynamics.\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://docscontent.nvidia.com/dims4/default/9c9b4d6/2147483647/strip/true/crop/1188x788+0+0/resize/1188x788!/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000187-c443-dd05-a3bf-e57fb6480000%2Fdeeplearning%2Fmodulus%2Fmodulus-sym%2F_images%2Ffourcastnet_overview.png\" >\n",
    "\n",
    "</div>\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d18b7-cebd-4297-a372-343b69b98a4d",
   "metadata": {},
   "source": [
    "### FourCastNet modeled variables:    \n",
    "| Vertical Level | Variable                |\n",
    "|:-------------- |:-----------------------|\n",
    "| Surface        | U10, V10, T2M, SP, MSLP |\n",
    "| 1000 hPa       | U, V, Z                |\n",
    "| 850 hPa        | T, U, V, Z, RH         |\n",
    "| 500 hPa        | T, U, V, Z, RH         |\n",
    "| 50 hPa         | Z                      |\n",
    "| Integrated     | TCWV                   |\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3563bd5-0258-4109-8999-c3a9dc46156d",
   "metadata": {},
   "source": [
    "## copy model source code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9488c-3996-42f7-9df3-9a28311d5011",
   "metadata": {},
   "source": [
    "### install required modules for FourCastNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adb38c-58e7-4896-8099-b12de6d7ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wandb h5py mpi4py netCDF4 cdsapi  ruamel.yaml tqdm timm einops \n",
    "! pip install git+https://github.com/romerojosh/benchy.git\n",
    "! pip install cdsapi netcdf4 xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa86fa-0e66-4fe2-8f1d-da076a98ef3a",
   "metadata": {},
   "source": [
    "### copy FourCastNet source code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca93dec-ad84-4158-95cd-a4d9869a7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVlabs/FourCastNet.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a695c-cc80-44f2-9fb8-e31f659799b2",
   "metadata": {},
   "source": [
    "## download checkpoint and stat0\n",
    "\n",
    "The model weights hosted at Trained Model Weights :\n",
    "\n",
    "```\n",
    "FCN_weights_v0/\n",
    "│   backbone.ckpt  \n",
    "│   precip.ckpt  \n",
    "```\n",
    "\n",
    "The pre-computed normalization statistics hosted at additional. It is crucial that you use the statistics that are provided if you are using the pre-trained model weights that we have provided since these stats were used when trainig the model. The normalization statistics go hand-in-hand with the trained model weights. The stats folder contains:\n",
    "\n",
    "\n",
    "```\n",
    "stats_v0\n",
    "│   global_means.npy  \n",
    "│   global_stds.npy  \n",
    "│   land_sea_mask.npy  \n",
    "│   latitude.npy  \n",
    "│   longitude.npy  \n",
    "│   time_means.npy\n",
    "│   time_means_daily.h5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e7555-269d-4e7d-a592-b607cf64c879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9624fc86-8497-411a-b860-966b4825bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "!wget -N -P FCN_weights_v0          https://portal.nersc.gov/project/m4134/FCN_weights_v0/backbone.ckpt \n",
    "#!wget -N -P FCN_weights_v0         https://portal.nersc.gov/project/m4134/FCN_weights_v0/precip.ckpt               \n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/global_means.npy \n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/global_stds.npy  \n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/land_sea_mask.npy\n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/latitude.npy    \n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/longitude.npy    \n",
    "!wget -N -P FCN_weights_v0/stats_v0 https://portal.nersc.gov/project/m4134/FCN_weights_v0/stats_v0/time_means.npy   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea687264-c103-4e65-abc6-5c0e10e91b15",
   "metadata": {},
   "source": [
    "# Typoon Dataset\n",
    "\n",
    "### get typoon data with JMA Besttrack(~2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50dbfe-bf18-4d07-931a-97642063f4f5",
   "metadata": {},
   "source": [
    "## download dataset with CDS API \n",
    "\n",
    "FourCastNet modeled variables\n",
    "<table align=\"left\" border=\"1\">\n",
    "  <tr>\n",
    "    <th>Vertical Level</th>\n",
    "    <th>Variable</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Surface</td>\n",
    "    <td>U10, V10, T2M, SP, MSLP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1000 hPa</td>\n",
    "    <td>U, V, Z</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>850 hPa</td>\n",
    "    <td>T, U, V, Z, RH</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>500 hPa</td>\n",
    "    <td>T, U, V, Z, RH</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>50 hPa</td>\n",
    "    <td>Z</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Integrated</td>\n",
    "    <td>TCWV</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f76543a-e01d-4f7e-a574-78cad3589405",
   "metadata": {},
   "source": [
    "# Data conversion ( NetCDF4 to HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a80fd-a4ad-4274-ba22-7c0e2833bf1b",
   "metadata": {},
   "source": [
    "## pytorch data loader \n",
    "- ECMWF ERA5 dataset : multiple NetCDF4\n",
    "  - SL : variables(5)  x H(721) x W(1440)\n",
    "  - PL : presure levels(4) x variables(4) x H(721) x W(1440)\n",
    "  - eliminate lat/lon data (same for whole datasets) \n",
    "- Pytorch DataLoader : HDF5 data ( structured data) \n",
    "  - time_frame x variables(20) x H(721) x W(1440)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13886f01-2041-4d9a-b5d0-a28e7e1d39cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file merge_h5.py \n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset as DS\n",
    "from glob import glob\n",
    "\n",
    "netcdf_dir = './custom_interval'\n",
    "hdf5_dir = './hdf5_dir'\n",
    "prefix = 'merged'\n",
    "file_ext = 'h5'\n",
    "dset_name = 'fields'\n",
    "\n",
    "def get_matched_files(netcdf_dir, DEBUG=False):\n",
    "    pl_files = sorted(glob(os.path.join(netcdf_dir, '*_pl.nc')))\n",
    "    sl_files = sorted(glob(os.path.join(netcdf_dir, '*_sl.nc')))\n",
    "    \n",
    "    matched_files = []\n",
    "    for pl_file in pl_files:\n",
    "        sl_file = pl_file[:-len('_pl.nc')] + '_sl.nc'\n",
    "        if sl_file in sl_files:\n",
    "            matched_files.append((pl_file, sl_file))\n",
    "    if DEBUG :\n",
    "        print( f\"DEBUG {len(matched_files)}\")\n",
    "    \n",
    "    return matched_files\n",
    "\n",
    "def generate_output_filename(orig_filename, idx,  hdf5_dir, prefix):\n",
    "    base_name = os.path.basename(orig_filename) \n",
    "    base_name_without_ext = os.path.splitext(base_name)[0][:-3] # this removes the last '_pl' or '_sl' part\n",
    "    return os.path.join(hdf5_dir, f\"{prefix}_{idx:02d}_{base_name_without_ext}.h5\")\n",
    "\n",
    "def writetofile(src, dest, channel_idx, varslist, src_idx=0, frmt='nc', DEBUG=False):       \n",
    "    for variable_name in varslist:\n",
    "        if os.path.isfile(src):\n",
    "            if frmt == 'nc':\n",
    "                fsrc = DS(src, 'r', format=\"NETCDF4\").variables[variable_name]\n",
    "            elif frmt == 'h5':\n",
    "                fsrc = h5py.File(src, 'r')[varslist[0]]\n",
    "\n",
    "            fdest = h5py.File(dest, 'a')\n",
    "            if dset_name not in fdest:\n",
    "                print(\"DEBUG: create file\")\n",
    "                Nimgtot = fsrc.shape[0]\n",
    "                fdest.create_dataset(dset_name, (Nimgtot, 20, 721, 1440), dtype='f')\n",
    "\n",
    "            if len(fsrc.shape) == 4:\n",
    "                ims = fsrc[:, src_idx]\n",
    "            else:\n",
    "                ims = fsrc[:]\n",
    "\n",
    "            fdest['fields'][:, channel_idx, :, :] = ims\n",
    "        channel_idx += 1\n",
    "    if DEBUG : \n",
    "        print(\"done\", varslist, ims.shape)\n",
    "\n",
    "def process_files(files, hdf5_dir, prefix, file_ext, DEBUG=False):\n",
    "    for i, (pl_file, sl_file) in enumerate(files):\n",
    "        output_file = generate_output_filename(pl_file, i, hdf5_dir, prefix)\n",
    "        if DEBUG : \n",
    "            print( f\"DEBUG {i} {sl_file}  {pl_file} {output_file}\") \n",
    "\n",
    "        writetofile(sl_file, output_file, 0, ['u10'])\n",
    "        writetofile(sl_file, output_file, 1, ['v10'])\n",
    "        writetofile(sl_file, output_file, 2, ['t2m'])\n",
    "        writetofile(sl_file, output_file, 3, ['sp'])\n",
    "        writetofile(sl_file, output_file, 4, ['msl'])\n",
    "\n",
    "        writetofile(pl_file, output_file, 5, ['t'], 2)\n",
    "        writetofile(pl_file, output_file, 6, ['u'], 3)\n",
    "        writetofile(pl_file, output_file, 7, ['v'], 3)\n",
    "        writetofile(pl_file, output_file, 8, ['z'], 3)\n",
    "\n",
    "        writetofile(pl_file, output_file, 9, ['u'], 2)\n",
    "        writetofile(pl_file, output_file, 10, ['v'], 2)\n",
    "        writetofile(pl_file, output_file, 11, ['z'], 2)\n",
    "\n",
    "        writetofile(pl_file, output_file, 12, ['u'], 1)\n",
    "        writetofile(pl_file, output_file, 13, ['v'], 1)\n",
    "        writetofile(pl_file, output_file, 14, ['z'], 1)\n",
    "\n",
    "        writetofile(pl_file, output_file, 15, ['t'], 1)\n",
    "        writetofile(pl_file, output_file, 16, ['z'], 0)\n",
    "        writetofile(pl_file, output_file, 17, ['r'], 1)\n",
    "        writetofile(pl_file, output_file, 18, ['r'], 2)\n",
    "\n",
    "        writetofile(sl_file, output_file, 19, ['tcwv'])\n",
    "\n",
    "def main():\n",
    "    DEBUG= True\n",
    "    print(\"get lists\")\n",
    "    files_to_process = get_matched_files(netcdf_dir, DEBUG=DEBUG)\n",
    "    os.makedirs(hdf5_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"start process\")\n",
    "    process_files(files_to_process, hdf5_dir, prefix, file_ext, DEBUG=DEBUG)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db859b-2fa8-4f93-91c1-d6e77ac37346",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 merge_h5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d66fb0-7b27-4603-901a-7bcf567cf291",
   "metadata": {},
   "source": [
    "## visualize variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb4efc-9e0d-4220-884f-cd553037e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def get_variable(file_path, variable_name):\n",
    "    # Open the HDF5 file\n",
    "    hdf5_file = h5py.File(file_path, 'r')\n",
    "\n",
    "    # Retrieve the variable data\n",
    "    variable = hdf5_file[variable_name][:]\n",
    "\n",
    "    # Close the file\n",
    "    hdf5_file.close()\n",
    "\n",
    "    return variable\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_variable(variable, frame_index, variable_index):\n",
    "    variable_names = ['u10', 'v10', 't2m', 'sp', 'msl', 't850', 'u1000', 'v1000', 'z1000', 'u850', 'v850', 'z850', 'u500', 'v500', 'z500', 't500', 'z50', 'r500', 'r850', 'tcwv']\n",
    "    vmin_values = [-30, -30, 220, None, None, 220, -30, -30, None, -30, -30, None, -30, -30, None, 220, None, 0, None, None]\n",
    "    vmax_values = [30, 30, 300, None, None, 300, 30, 30, None, 30, 30, None, 30, 30, None, 270, None, 120, None, None]\n",
    "    cmaps = [None, None, 'coolwarm', None, None, 'coolwarm', None, None, None, None, None, None, None, None, None, 'coolwarm', None, None, None, None]\n",
    "\n",
    "    variable_name = variable_names[variable_index]\n",
    "    vmin = vmin_values[variable_index]\n",
    "    vmax = vmax_values[variable_index]\n",
    "    cmap = cmaps[variable_index]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "    if vmin is not None and vmax is not None:\n",
    "        plt.imshow(variable[frame_index][variable_index], vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(variable[frame_index][variable_index], cmap=cmap)\n",
    "\n",
    "    plt.colorbar(shrink=0.75)\n",
    "    plt.title(f\"Variable {variable_name} at Frame {frame_index}\")\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00e616-c50c-4ab0-8ca0-18e154e11735",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = get_variable('./hdf5_dir/merged_01_2214_2022091212_2022092000.h5', 'fields' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9d03e-500d-4446-9de6-a4ed9381e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64925314-486d-42a2-ba95-895917767c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plot_variable(variables,8,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8ad25-7300-483a-9a29-c0acd812613d",
   "metadata": {},
   "source": [
    "## normalize \n",
    "FourCastNet dataloader use stats_v0 ( mean,std) for each variables \n",
    "\n",
    "\n",
    "```\n",
    "stats_v0\n",
    "│   global_means.npy  \n",
    "│   global_stds.npy  \n",
    "│   land_sea_mask.npy  \n",
    "│   latitude.npy  \n",
    "│   longitude.npy  \n",
    "│   time_means.npy\n",
    "│   time_means_daily.h5\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57aa08a-98ef-4993-8baa-853df9a980df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
