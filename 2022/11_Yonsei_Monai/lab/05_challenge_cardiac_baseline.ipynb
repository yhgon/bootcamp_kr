{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ohkCyqZNaM"
   },
   "source": [
    "#  MONAI Bootcamp\n",
    "\n",
    "# Segmentation Exercise  [baseline]\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>\n",
    "\n",
    "\n",
    "In this exercise we will segment the left ventricle of the heart in relatively small images using neural networks. \n",
    "Below is the code for setting up a segmentation network and training it. The network isn't very good, **so the exercise is to improve the quality of the segmentation by improving the network and/or the training scheme including data loading efficiency and data augmentation**. \n",
    "\n",
    "The data being used here is derived from the [Sunnybrook Cardiac Dataset](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/) of cardiac MR images, filtered to contain only left ventricular myocardium segmentations and reduced in the XY dimensions.\n",
    "\n",
    "<img src=\"https://www.cardiacatlas.org/wp-content/uploads/2015/09/scd-mri.png\" width=400>\n",
    "\n",
    "\n",
    "First we install and import MONAI plus other dependencies:\n",
    "\n",
    "\n",
    "#### Required Packages \n",
    "This notebook has the pip command for installing MONAI and will be added to any subsequent notebook.\n",
    "Execute the following cell to install MONAI the first time a colab notebook is run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aLtpMbJVNCH",
    "outputId": "40da1e90-8167-45af-e4ca-d783eef3029c"
   },
   "outputs": [],
   "source": [
    "#!pip install -qU \"monai[ignite, nibabel, torchvision, tqdm]==0.8.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7pcbsphZh8G"
   },
   "source": [
    "### Check GPU Support\n",
    "\n",
    "Running\n",
    "\n",
    "`!nvidia-smi`\n",
    "\n",
    "in a cell will verify this has worked and show you what kind of hardware you have access to.\n",
    "if GPU Memory Usage is no `0 MiB` shutdown all kernels and restart current kernel.\n",
    "- step1. shutdown kernel with following <b>Menu</b> > <b>Kernel</b> > <b>Shut Down All kernels </b>\n",
    "- step2. restart kernelw with following <b>Menu</b> > <b>Kernel</b> > <b>Restart Kernel</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZVD7911EVcWI",
    "outputId": "2783c3a4-855a-4b2b-86c0-297b7b31b9ce"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX4DkxZygKNP"
   },
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pNnKTuzBgKZm",
    "outputId": "8b7c3607-768e-4222-d4c0-82806f5a1264"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import monai\n",
    "from monai.transforms import Compose, AddChannel, ScaleIntensity, ToTensor\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import ArrayDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.utils import first, progress_bar\n",
    "from monai.networks import one_hot\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "set_determinism(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up our Dataset and exploring the data\n",
    "#### Setup data directory\n",
    "\n",
    "We'll create a temporary directory for all the MONAI data we're going to be using called temp directory in `~/monai-lab/temp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "directory = \"temp\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpNZjqg3Lq-1"
   },
   "source": [
    "## download dataset \n",
    "\n",
    "We will use preprocessed Sunnybrook Cardiac MRI dataset (2MB) at  [VPH Summer SChool 2019](https://www.vph-institute.org/events/2019-vph-summer-school.html)\n",
    "\n",
    "You can check for further research\n",
    "- Sunnybrook Cardiac MRI dataset(30MB) in [kaggle](https://www.kaggle.com/datasets/salikhussaini49/sunnybrook-cardiac-mri)\n",
    "- Sunnybrook Cardiac Data DICOM file(2.6GB) at [Cardiac Atlas Project](https://www.cardiacatlas.org/studies/sunnybrook-cardiac-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "DATA_NPZ = \"https://github.com/ericspod/VPHSummerSchool2019/raw/master/scd_lvsegs.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data from the remote source and visualize a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "remote_file = urlopen(DATA_NPZ)\n",
    "npz = BytesIO(remote_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(npz)  # load all the data from the archive\n",
    "\n",
    "images = data[\"images\"]  # images in BHW array order\n",
    "segs = data[\"segs\"]  # segmentations in BHW array order\n",
    "case_indices = data[\"caseIndices\"]  # the indices in `images` for each case\n",
    "\n",
    "images = images.astype(np.float32) / images.max()  # normalize images\n",
    "\n",
    "print(images.shape, segs.shape)\n",
    "plt.imshow(images[13] + segs[13] * 0.25, cmap=\"gray\")  # show image 13 with segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our data into a training and validation set by keeping the last 6 cases as the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index = case_indices[-6, 0]  # keep the last 6 cases for testing\n",
    "\n",
    "# divide the images, segmentations, and categories into train/test sets\n",
    "train_images, train_segs = images[:valid_index], segs[:valid_index]\n",
    "valid_images, valid_segs = images[valid_index:], segs[valid_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a MONAI data loading object to compose batches during training, and another for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_workers = 2\n",
    "\n",
    "image_trans = Compose(\n",
    "    [\n",
    "        ScaleIntensity(),  # rescale image data to range [0,1]\n",
    "        AddChannel(),  # add 1-size channel dimension\n",
    "        ToTensor(),  # convert to tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "seg_trans = Compose([AddChannel(), ToTensor()])\n",
    "\n",
    "ds = ArrayDataset(train_images, image_trans, train_segs, seg_trans)\n",
    "loader = DataLoader(\n",
    "    dataset=ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "val_ds = ArrayDataset(valid_images, image_trans, valid_segs, seg_trans)\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "im, seg = first(loader)\n",
    "print(im.shape, im.min(), im.max(), seg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define out simple network. This doesn't do a good job so consider how to improve it by adding layers or other elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monai Network\n",
    "MONAI provides predefined networks. we can easily import it. \n",
    "\n",
    "- [Layers](https://docs.monai.io/en/stable/networks.html#layers) : Act, Conv, Norm, Dropout, Flatten, Reshape, Pad, Pool, SkipConnection\n",
    "- [Blocks](https://docs.monai.io/en/stable/networks.html#module-monai.networks.blocks) : ADN, Convolution, Synamic UnetBlock, FCN, GCN, Squeeze-andExcitation, ResNeXt, SABlock, Transformer Block, \n",
    "- [Nets](https://docs.monai.io/en/stable/networks.html#nets)  : DenseNet121, EfficientNet, SegResNet, ResNet, SENet154, DyUNet, UNet, AutoEncoder, VarAutoEncoder, ViT, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define out simple network. This doesn't do a good job so consider how to improve it by adding layers or other elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model \n",
    "\n",
    "SegNet : \n",
    " - Input \n",
    " - Conv2D\n",
    " - MaxPool2D\n",
    " - Conv3D\n",
    " - ConvT2D\n",
    " - Conv2d\n",
    " - Output \n",
    "\n",
    "<p><img align='left' src=\"https://miro.medium.com/max/1400/1*nGFy96r63GwSE_EsJDLMDw.png\" width=600>  </p>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # layer 1: convolution, normalization, downsampling\n",
    "            nn.Conv2d(1, 2, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            # layer 2\n",
    "            nn.Conv2d(2, 4, 3, 1, 1),\n",
    "            # layer 3\n",
    "            nn.ConvTranspose2d(4, 2, 3, 2, 1, 1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            # layer 4: output\n",
    "            nn.Conv2d(2, 1, 3, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss and metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "loss = DiceLoss(sigmoid=True)\n",
    "metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3\n",
    "opt = torch.optim.Adam(net.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_losses = []\n",
    "epoch_metrics = []\n",
    "total_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "print(\"start train\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "\n",
    "    # train network with training images\n",
    "    for bimages, bsegs in loader:\n",
    "        bimages = bimages.to(device)\n",
    "        bsegs = bsegs.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        prediction = net(bimages)\n",
    "        loss_val = loss(torch.sigmoid(prediction), bsegs)\n",
    "        loss_val.backward()\n",
    "        opt.step()\n",
    "\n",
    "        step_losses.append((total_step, loss_val.item()))\n",
    "        total_step += 1\n",
    "\n",
    "    net.eval()\n",
    "    metric_vals = []\n",
    "\n",
    "    # test our network using the validation dataset\n",
    "    with torch.no_grad():\n",
    "        for bimages, bsegs in val_loader:\n",
    "            bimages = bimages.to(device)\n",
    "            bsegs = bsegs.to(device)\n",
    "\n",
    "            prediction = net(bimages)\n",
    "\n",
    "            mvals = metric(y_pred=torch.sigmoid(prediction) > 0.5, y=bsegs)\n",
    "            metric_vals += mvals.cpu().data.numpy().flatten().tolist()\n",
    "\n",
    "    epoch_metrics.append((total_step, np.average(metric_vals)))\n",
    "\n",
    "    progress_bar(epoch + 1, num_epochs, f\"Validation Metric: {epoch_metrics[-1][1]:7.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now graph the results from our training and find the results are not very good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "ax[0].semilogy(*zip(*step_losses))\n",
    "ax[0].set_title(\"Step Loss\")\n",
    "\n",
    "ax[1].plot(*zip(*epoch_metrics))\n",
    "ax[1].set_title(\"Per-Step Validation Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‰ Challenge: Improve Results and Implementation ðŸ‘ˆ\n",
    "\n",
    "### 1. Improve Data Pipeline\n",
    "\n",
    "The pipeline currently has a very basic set of transforms. We'd want to add new transforms which will add regularization to our training process, specifically modifying the image and segmentations to make the learning problem a little harder. \n",
    "\n",
    "The dataset being used is `ArrayDataset` but we have in MONAI `NPZDictItemDataset` for loading data from Numpy's NPZ file format. Change the code to use this class instead. You'll need a different way of getting `caseIndices` and splitting the dataset using it.\n",
    "\n",
    "\n",
    "### 2. Improve/Replace Network\n",
    "\n",
    "As you can see we're not getting good results from our network. The training loss values are jumping around and not decreasing much anymore. The validation score has topped out at 0.25, which is really poor. \n",
    "\n",
    "It's now up to you to improve the results of our segmentation task. The things to consider changing include the network itself, how data is loaded, how batches might be composed, and what transforms we want to use from MONAI. \n",
    "\n",
    "### 3. Replace The Training Loop\n",
    "\n",
    "This notebook uses a simple training loop with validation done explicitly. Replace this with a use of the `SupervisedTrainer` class and `SupervisedEvaluator` to do the evaluation throughout the training process. The graph plotting is done simply by recording values at each iteration through the loop, you'll want to use some other mechanism to do the same thing such as using a `MetricLogger` handler object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caution !!!\n",
    "### please shutdown all kernels with [Kernel] menu >  [Shutdown All Kernel]  before launch next notebook\n",
    "\n",
    "## Navigation\n",
    "- [01_getting started](./01_getting.ipynb)\n",
    "\n",
    "- [02_pipeline_01](./02_pipeline_01.ipynb)\n",
    "- [02_pipeline_02 ](./02_pipeline_02.ipynb)\n",
    "- [02_pipeline_03](./02_pipeline_03.ipynb)\n",
    "- [02_pipeline_04  ](./02_pipeline_04.ipynb)\n",
    "\n",
    "- [03_brain_gan ](./03_brain_gan_01.ipynb)\n",
    "\n",
    "- [04_spleen_segment ](./04_spleen_segment.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac baseline  ](./05_challenge_cardiac_baseline.ipynb) \n",
    "\n",
    "- [05_challenge_cardiac workspace next ](./05_challenge_cardiac_workspace.ipynb) \n",
    "\n",
    "<img src=\"https://github.com/Project-MONAI/MONAIBootcamp2021/raw/2f28b64f814a03703667c8ea18cc84f53d6795e4/day1/monai.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "moani_bootcamp_2_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
