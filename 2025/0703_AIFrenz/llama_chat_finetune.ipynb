{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **AIFrenz GPU bootcamp**\n",
        "##   End-to-End LLM finetune\n",
        "\n",
        "by Hyungon Ryu | NVIDIA Sr. Solution Architect\n",
        "\n",
        "본 컨텐츠는 NVIDIA OpenHackathon 팀이 운영하는 GPU Bootcamp contents를 Google Colab에 맞게 변경하였기 때문에, 몇몇 수동 설정 및 코드 변경하는 스크립트들이 존재합니다. 오리지널 컨텐츠는 다음의 링크를 통해 확인하실 수 있습니다. [End-to-End-LLM](https://github.com/openhackathons-org/End-to-End-LLM)"
      ],
      "metadata": {
        "id": "ZPfs9FcC2dKb"
      },
      "id": "ZPfs9FcC2dKb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU 환경 확인\n",
        "`$ !nvidia-smi` 명령을 통해 현재 설치되어 있는 GPU를 확인할 수 있습니다.\n",
        "아래와 같이 GPU 종류, 메모리 크기, 설치된 드라이버 정보 등\n",
        "\n",
        "```\n",
        "-----------------------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
        "|-----------------------------------------+------------------------+----------------------+\n",
        "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
        "|                                         |                        |               MIG M. |\n",
        "|=========================================+========================+======================|\n",
        "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
        "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
        "|                                         |                        |                  N/A |\n",
        "+-----------------------------------------+------------------------+----------------------+\n",
        "                                                                                         \n",
        "+-----------------------------------------------------------------------------------------+\n",
        "| Processes:                                                                              |\n",
        "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
        "|        ID   ID                                                               Usage      |\n",
        "|=========================================================================================|\n",
        "|  No running processes found                                                             |\n",
        "+-----------------------------------------------------------------------------------------+\n",
        "```\n"
      ],
      "metadata": {
        "id": "txrZ7Aey2zzj"
      },
      "id": "txrZ7Aey2zzj"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fDuZAc62aCE",
        "outputId": "56d8f916-fc20-43fb-d287-a7e42b93908f"
      },
      "id": "3fDuZAc62aCE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  2 06:36:19 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습에 필요한 라이브러리 설치\n",
        "LLM finetune을 위해서 hugginface transformer, datasets, peft, trl을 설치합니다.\n",
        "quantization을 위해서 bitsandbytes를 설치합니다.\n",
        "모델 파라미터, 데이터셋을 다운로드하기 위해서 google gdown을 설치합니다.\n",
        "설치는 네트웍 환경에 따라 약 5분 정도 시간이 소요됩니다.\n",
        "\n",
        "colab환경에서 NEMO toolkit 설치는 시간이 오래 걸리므로 생략하였습니다."
      ],
      "metadata": {
        "id": "5xHVuh4l3d9C"
      },
      "id": "5xHVuh4l3d9C"
    },
    {
      "cell_type": "code",
      "source": [
        " %%time\n",
        "!pip install --upgrade pip\n",
        "!pip install transformers datasets langdetect peft trl bitsandbytes gdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KfBOxgD1v-o",
        "outputId": "a944e0f9-6cc1-4bec-cbaa-e082f3d0996d"
      },
      "id": "3KfBOxgD1v-o",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Collecting trl\n",
            "  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.8.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading trl-0.19.0-py3-none-any.whl (375 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m143.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m155.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m149.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m149.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m141.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m174.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=ac605f327b45c2f175a94a08e07e71d2cf6100194a30c5f1a4bc1faec3e6d7cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, bitsandbytes, trl\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: fsspec\n",
            "\u001b[2K    Found existing installation: fsspec 2025.3.2\n",
            "\u001b[2K    Uninstalling fsspec-2025.3.2:\n",
            "\u001b[2K      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: datasets\n",
            "\u001b[2K    Found existing installation: datasets 2.14.4\n",
            "\u001b[2K    Uninstalling datasets-2.14.4:\n",
            "\u001b[2K      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [trl]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.46.0 datasets-3.6.0 fsspec-2025.3.0 langdetect-1.0.9 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.19.0\n",
            "CPU times: user 3.69 s, sys: 1.1 s, total: 4.8 s\n",
            "Wall time: 1min 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1OR4-HA4Prn"
      },
      "id": "W1OR4-HA4Prn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습에 필요한 utility 파일들을 라운로드합니다.\n",
        "모두 OpenHackathon팀이 제작한 GPU Bootcamp 컨텐츠를 사용합니다.  "
      ],
      "metadata": {
        "id": "_CP7whgp5WvV"
      },
      "id": "_CP7whgp5WvV"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gdown\n",
        "\n",
        "os.makedirs(\"source\", exist_ok=True)\n",
        "scripts = {\n",
        "    \"source/download-guanco-ds.py\": \"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-guanco-ds.py\",\n",
        "    \"source/download-llama2-chat.py\": \"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-llama2-chat.py\",\n",
        "    \"source/download-llama2.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-llama2.py\",\n",
        "    \"source/convert_llama_weights_to_hf.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/convert_llama_weights_to_hf.py\",\n",
        "    \"source/configuration_llama.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/configuration_llama.py\",\n",
        "    \"source/modeling_flax_llama.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/modeling_flax_llama.py\",\n",
        "    \"source/modeling_llama.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/modeling_llama.py\",\n",
        "    \"source/tokenization_llama.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/tokenization_llama.py\",\n",
        "    \"source/tokenization_llama_fast.py\":\"https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/tokenization_llama_fast.py\",\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "for fname, url in scripts.items():\n",
        "    print(f\"Downloading {fname} …\")\n",
        "    gdown.download(url, fname, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5UJ5Yfg4QU1",
        "outputId": "b38e5b63-fc11-4813-cd5e-157c44814e1c"
      },
      "id": "A5UJ5Yfg4QU1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-guanco-ds.py\n",
            "To: /content/source/download-guanco-ds.py\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/download-guanco-ds.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "518B [00:00, 1.57MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/download-llama2-chat.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-llama2-chat.py\n",
            "To: /content/source/download-llama2-chat.py\n",
            "267B [00:00, 713kB/s]                    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/download-llama2.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/download-llama2.py\n",
            "To: /content/source/download-llama2.py\n",
            "262B [00:00, 474kB/s]                    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/convert_llama_weights_to_hf.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/convert_llama_weights_to_hf.py\n",
            "To: /content/source/convert_llama_weights_to_hf.py\n",
            "13.3kB [00:00, 21.1MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/configuration_llama.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/configuration_llama.py\n",
            "To: /content/source/configuration_llama.py\n",
            "9.39kB [00:00, 11.5MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/modeling_flax_llama.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/modeling_flax_llama.py\n",
            "To: /content/source/modeling_flax_llama.py\n",
            "30.1kB [00:00, 48.2MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/modeling_llama.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/modeling_llama.py\n",
            "To: /content/source/modeling_llama.py\n",
            "65.4kB [00:00, 60.7MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/tokenization_llama.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/tokenization_llama.py\n",
            "To: /content/source/tokenization_llama.py\n",
            "22.0kB [00:00, 24.8MB/s]                   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading source/tokenization_llama_fast.py …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/openhackathons-org/End-to-End-LLM/raw/refs/heads/main/workspace-llm-use-case/source_code/Llama2/llama/tokenization_llama_fast.py\n",
            "To: /content/source/tokenization_llama_fast.py\n",
            "13.1kB [00:00, 37.1MB/s]                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gh27DSDj4QXw"
      },
      "id": "gh27DSDj4QXw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실습 모델 다운로드\n",
        "실습에 필요한 Llama-2 checkpoint를 다운로드 받습니다.\n",
        "Huggingface 사이트에서 직접 받는 것도 가능합니다.\n",
        "*주의*\n",
        "용량이 큰 2개의 파일을 받기 때문에 약 10분 이상의 시간이 걸립니다.\n",
        "다운로드 후 런타임을 다시 시작하면 다시 받으셔야 할 수 있습니다.  \n",
        "Google Drive를 연동하는 경우 복사해 놓으시면 다운로드한 이미지를 계속 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "nDZzj-bL5r5L"
      },
      "id": "nDZzj-bL5r5L"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RU_5yjNw6Q_Z"
      },
      "id": "RU_5yjNw6Q_Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   Download Llama-2 checkpoints via gdown\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "links = {\n",
        "    \"model/Llama-2-7b-chat.tar\": \"https://drive.google.com/uc?id=1rfMCxT8fUQwQ5Pe6z7kDgK3nAZ6FyEeT&confirm=t\",\n",
        "}\n",
        "\n",
        "for out, url in links.items():\n",
        "    print(f\"Downloading {out} …\")\n",
        "    gdown.download(url, out, quiet=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNFL8cvX54dG",
        "outputId": "2cb85040-5752-4af7-c82a-8a148f9aee19"
      },
      "id": "UNFL8cvX54dG",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model/Llama-2-7b-chat.tar …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rfMCxT8fUQwQ5Pe6z7kDgK3nAZ6FyEeT&confirm=t\n",
            "To: /content/model/Llama-2-7b-chat.tar\n",
            "100%|██████████| 27.0G/27.0G [03:15<00:00, 138MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model/Llama-2-7b.tar …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kRyLpeg1ur8HC-wgsskR2dPmpmvL8qi6&confirm=t\n",
            "To: /content/model/Llama-2-7b.tar\n",
            "100%|██████████| 27.0G/27.0G [03:11<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "하드디스크를 절약하기 위해서 압축을 푼 후 압축 파일을 삭제합니다."
      ],
      "metadata": {
        "id": "q5qtMVRu7KBw"
      },
      "id": "q5qtMVRu7KBw"
    },
    {
      "cell_type": "code",
      "source": [
        " %%time\n",
        "!tar -xf model/Llama-2-7b-chat.tar -C model && rm model/Llama-2-7b-chat.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odA36vhR7IEV",
        "outputId": "c8165c2d-0512-42a1-8514-237c94e28c93"
      },
      "id": "odA36vhR7IEV",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "^C\n",
            "CPU times: user 948 ms, sys: 150 ms, total: 1.1 s\n",
            "Wall time: 3min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference 테스트\n"
      ],
      "metadata": {
        "id": "wq9Ydx_a7uTP"
      },
      "id": "wq9Ydx_a7uTP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *주의*\n",
        "Hugginface transformer pipeline을 이용하기 위해서는 다운로드한 체크포인트를\n",
        "Hugginface Transformer 라이브러리에 맞게 변환을 해줘야합니다.\n",
        "변환 및 저장에 약 3분 정도의 시간이 소요됩니다."
      ],
      "metadata": {
        "id": "_cD0Ut7e-Aqp"
      },
      "id": "_cD0Ut7e-Aqp"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python source/convert_llama_weights_to_hf.py \\\n",
        "    --input_dir model/Llama-2-7b-chat \\\n",
        "    --model_size 7B \\\n",
        "    --output_dir model/Llama-2-7b-chat-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHnLDaPu9F2W",
        "outputId": "7ab67476-4feb-46da-80c6-2b09d0febae9"
      },
      "id": "oHnLDaPu9F2W",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-02 07:07:32.998548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751440053.018031    9341 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751440053.024183    9341 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "Fetching all parameters from the checkpoint at model/Llama-2-7b-chat.\n",
            "Loading the checkpoint in a Llama model.\n",
            "Loading checkpoint shards: 100% 33/33 [00:00<00:00, 380.38it/s]\n",
            "Saving in the Transformers format.\n",
            "CPU times: user 665 ms, sys: 91.6 ms, total: 756 ms\n",
            "Wall time: 2min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYps0Nlr8lHQ",
        "outputId": "4459388e-6e8a-49af-fbc8-440de0bd9b64"
      },
      "id": "hYps0Nlr8lHQ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  2 07:11:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0             27W /   70W |   14928MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chat prompt 테스트를 진행합니다.\n",
        "\n",
        "HF pipeline을 통해서 간단한 prompt를 실행해보는 예제입니다."
      ],
      "metadata": {
        "id": "IVKKuaM6-N4R"
      },
      "id": "IVKKuaM6-N4R"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "BASE = \"model/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE, trust_remote_code=True)\n",
        "model     = AutoModelForCausalLM.from_pretrained(BASE)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=100)\n",
        "out = pipe(\"<s>[INST] What is astrophotography? [/INST]\")[0][\"generated_text\"]\n",
        "print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "90fee691288c4023a849609a71a963fb",
            "e0f17f35d5a5485b91ff5c7260131a5f",
            "3f96458c41d647d1927861be69765c49",
            "70933ead63e44f2bb4bd49a8ad2c5468",
            "a9b45f78860f4c7ea58819468c63e3ab",
            "91121e22962240dca0e39159d0590c6c",
            "13bcd583415f4e68a8366f7ecd805f3f",
            "4ee6a7900a7b4137849fa44d720dfb68",
            "1f9afbfabf5d498180c17f29f51eeb9b",
            "ce4d59b2bbfb449abf1a240d6fc401f8",
            "e00a9dbe93a9496b8785886f8abce2ef"
          ]
        },
        "collapsed": true,
        "id": "qUB0W9Bw7l83",
        "outputId": "3f5babe0-84c6-49e6-85f1-8ddfcf3467f4"
      },
      "id": "qUB0W9Bw7l83",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90fee691288c4023a849609a71a963fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 166.12 MiB is free. Process 12237 has 14.58 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 1.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-3490231756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<s>[INST] What is astrophotography? [/INST]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"generated_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"processor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         self.check_model_type(\n\u001b[1;32m    116\u001b[0m             \u001b[0mTF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mMODEL_FOR_CAUSAL_LM_MAPPING_NAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mhf_device_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         ):\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;31m# If it's a generation pipeline and the model can generate:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3849\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m                 )\n\u001b[0;32m-> 3851\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 166.12 MiB is free. Process 12237 has 14.58 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 1.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kK9di3bbQPvJ"
      },
      "id": "kK9di3bbQPvJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-bit 양자화\n",
        "\n",
        "\n",
        "Several ways and algorithms to quantize a model including can be found [here](https://huggingface.co/docs/peft/main/en/developer_guides/quantization). A library to easily implement quantization and integrate with transformers is the `bitsandbytes` library. The library provides config parameters to quantize a model to 8 or 4 bits using the `BitsAndBytesConfig` class. The 4 bits parameters used in the cell below are described as follows:\n",
        "\n",
        "- **load_in_4bit**: set `True` to quantize the model to 4-bits when you load it\n",
        "- **bnb_4bit_quant_type**: set to `\"nf4\"` to use a special 4-bit data type for weights initialized from a normal distribution\n",
        "- **bnb_4bit_use_double_quant**: set `True` to use a nested quantization scheme to quantize the already quantized weights\n",
        "- **bnb_4bit_compute_dtype**: set to `torch.float16` or `torch.bfloat16` to use bfloat16 for faster computation\n",
        "\n",
        "Run the cell below to set the 4-bit quantization for our model."
      ],
      "metadata": {
        "id": "y0gMLeVJAWm6"
      },
      "id": "y0gMLeVJAWm6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **주의**\n",
        "메모리 이슈로 인해 런타임을 재시작을 하는 경우  **`세션 다시시작`**을 누르시면 됩니다.\n",
        "절대로 런타임 연결해제를 누르면 안됩니다. 설치된 라이브러리와 다운로드한 체크포인트, 데이터가 모두 사라집니다.\n"
      ],
      "metadata": {
        "id": "SDOOx6A0-jhV"
      },
      "id": "SDOOx6A0-jhV"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from langdetect import detect\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "import re\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "owtgtoPy-jui"
      },
      "id": "owtgtoPy-jui",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vh2aroX6-srm"
      },
      "id": "vh2aroX6-srm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15GB 메모리 내에서 inference /finetune을 진행하기 위해서\n",
        "bitsandbytes를 활성화해야합니다."
      ],
      "metadata": {
        "id": "0Dnj9p76-xbW"
      },
      "id": "0Dnj9p76-xbW"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ],
      "metadata": {
        "id": "0DT0c4Gi-6lB"
      },
      "id": "0DT0c4Gi-6lB",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"model/Llama-2-7b-chat-hf\""
      ],
      "metadata": {
        "id": "9W5RYXmI_IqS"
      },
      "id": "9W5RYXmI_IqS",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b0116b1082014b22af343485726d8d35",
            "c089add359e746bb98fa31eb3cb138c9",
            "27834aa314ed4339a2eb4a2cf0e8ffa2",
            "15578feea14f4d40bc21f3967afae7c2",
            "610f2f2501bb453d8b3dcdcb20ab5f44",
            "ab85240109cd48be95bb73c1c7f3d80a",
            "798caebbc7244c438f480fe6143054fd",
            "2c3f500c2cd8452b8e896204b9dbda3d",
            "f7bc89666b4c40c58697ec8386425913",
            "25b0cd3463ca4ea9bf34e40c11843837",
            "4f5181589fbf48c59d0774b8be671214"
          ]
        },
        "id": "WANQNA0D--3j",
        "outputId": "0b158bbb-95b2-4af5-e13a-dd75a0247e8c"
      },
      "id": "WANQNA0D--3j",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0116b1082014b22af343485726d8d35"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXM48syO_R91",
        "outputId": "60952dbd-5f15-44b7-e5a2-96c2cf522e0f"
      },
      "id": "zXM48syO_R91",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  2 07:15:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0             27W /   70W |    6676MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tokenizer를 로드합니다."
      ],
      "metadata": {
        "id": "no6DipQX_Xlx"
      },
      "id": "no6DipQX_Xlx"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(BASE, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "Kqh9mw9u_SF8"
      },
      "id": "Kqh9mw9u_SF8",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HF pipeline을 정의합니다."
      ],
      "metadata": {
        "id": "dgKk3YC8_mZU"
      },
      "id": "dgKk3YC8_mZU"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(prompt,max_length=200 ):\n",
        "    inf_pipeline = pipeline(model=model, tokenizer=tokenizer, max_length=max_length, task=\"text-generation\")\n",
        "    prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    result = inf_pipeline(prompt)\n",
        "    print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "jCx4LJUx_kyM"
      },
      "id": "jCx4LJUx_kyM",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"explain what is astrophotography?\"\n",
        "run_inference(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Txo-PqG_SKH",
        "outputId": "db57eecb-8f5d-47bd-cd00-d3c1b8496646"
      },
      "id": "8Txo-PqG_SKH",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] explain what is astrophotography? [/INST]  Astrophotography is a type of photography that involves capturing images of celestial objects such as stars, planets, galaxies, and other astronomical phenomena. Hinweis auf die Bildgröße der Sonne und des Mondes. Astrophotography can be done using a variety of techniques and equipment, including:\n",
            "\n",
            "1. DSLR cameras: These are the most common type of camera used for astrophotography. They have large sensors that can capture a lot of light, making it possible to capture detailed images of celestial objects.\n",
            "2. Mirrorless cameras: These cameras are similar to DSLRs but have a more compact design and are often more lightweight, making them easier to use for astrophotography.\n",
            "3. Cameras with full-frame sensors: These cameras have larger sensors than\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2T6FSu5AH-X",
        "outputId": "df5d5271-6436-422c-80e8-58bb6a51841f"
      },
      "id": "S2T6FSu5AH-X",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  2 07:18:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0             27W /   70W |    6760MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0U4GT8GA7qBf"
      },
      "id": "0U4GT8GA7qBf"
    },
    {
      "cell_type": "markdown",
      "id": "23bc1ddc",
      "metadata": {
        "id": "23bc1ddc"
      },
      "source": [
        "# Finetune llama2 model with custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c2184e",
      "metadata": {
        "id": "68c2184e"
      },
      "source": [
        "## 데이터 전처리 (Data Preprocessing)\n",
        "\n",
        "We consider [openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco) as our choice dataset for finetuning. The openassistant-guanaco dataset is a subset of the [Open Assistant Conversations](https://huggingface.co/datasets/OpenAssistant/oasst1/tree/main) dataset that contains only the highest-rated paths in the conversation tree, with a total of 9,85k training samples and 518 test samples. The OpenAssistant Conversations (OASST1) is a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers ([source](https://huggingface.co/datasets/OpenAssistant/oasst1))."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c17d349",
      "metadata": {
        "id": "7c17d349"
      },
      "source": [
        "### Dataset Structure\n",
        "\n",
        "Each row in the `openassistant-guanaco` jsonl dataset is a text dictionary that consists of `human` instructions and `Assistant` that provide context to draw the response to the instruction. Within the `text`, the `human` and `Assistant` fields are separated with three `###` delimiters that denote the start and end of positions.  \n",
        "\n",
        "```bash\n",
        "\n",
        "{ \"text\": \"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to...\n",
        "           ### Assistant: \\\"Monopsony\\\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term  is...   \n",
        "           ### Human: Now explain it to a dog\"\n",
        "}\n",
        "{ \"text\": \"### Human: \\u00bfCUales son las etapas del desarrollo y en qu\\u00e9 consisten seg\\u00fan Piaget?\n",
        "           ### Assistant: Jean Piaget fue un psic\\u00f3log suizo que propuso una teor\\u00eda sobre el desarrollo cognitivo...\n",
        "           ### Human: \\u00bfHay otras teor\\u00edas sobre las etapas del desarrollo que reafirmen o contradigan a la teor\\u00eda de Piaget?\"\n",
        "}\n",
        "{\"text\": \"### Human: Can you give me an example of a python script that opens an api point and serves a string?\n",
        "          ### Assistant: Sure! Here's an example Python script that uses the Flask web framework to create a simple API endpoint that serves a string:\\n\\n`         \\nfrom flask import Flask\\n\\napp = Flask(__name__)\\n\\n@app.route('/')\\ndef hello_world():\\n    return 'Hello, world!'\\n\\nif __name__ ==  \\n ...   \n",
        "          ### Human: What changes would you need to make to the code above to serve a JSON object instead of a string?\n",
        "          ### Assistant: To serve a JSON object instead of a string, you can modify the \\\"hello_world()\\\" function to return a JSON response using the  Flask \\\"jsonify\\\" function. Here's an example of how to modify the previous code to serve a JSON object:\\n\\n... \"\n",
        "}\n",
        "...\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run the cell below to check if the dataset exists in the data directory; otherwise, uncomment the nested cell below to download it.\n",
        "\n",
        "## *주의*\n",
        "소스코드를 확인하여 데이터 저장위치를 Colab환경에 맞게 다음과 같이 조정해주세요\n",
        "`/content/source/download-guanco-ds.py`\n",
        "\n",
        "변경전\n",
        "```\n",
        "output_eva = '../data/openassistant_best_replies_eval.jsonl'\n",
        "output_train = '../data/openassistant_best_replies_train.jsonl'\n",
        "\n",
        "```\n",
        "\n",
        "변경후\n",
        "```\n",
        "output_eva = '/content/data/openassistant_best_replies_eval.jsonl'\n",
        "output_train = '/content/data/openassistant_best_replies_train.jsonl'\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "lqLHmKi7DGJC"
      },
      "id": "lqLHmKi7DGJC"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f4cc5452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4cc5452",
        "outputId": "cd4636d8-0231-4e5d-9df8-7096637fc2d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PFLTYBJi0rLQlFjWrr8ioaIgoNbiffXx&confirm=t\n",
            "To: /content/data/openassistant_best_replies_eval.jsonl\n",
            "100% 1.11M/1.11M [00:00<00:00, 183MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tAJI0z_dyZAX9MW6tYmv3znH_561BDVY&confirm=t\n",
            "To: /content/data/openassistant_best_replies_train.jsonl\n",
            "100% 20.9M/20.9M [00:00<00:00, 77.0MB/s]\n",
            "CPU times: user 110 ms, sys: 21.5 ms, total: 132 ms\n",
            "Wall time: 25.8 s\n"
          ]
        }
      ],
      "source": [
        "###### download dataset. Remove comment to run the cell ###########\n",
        "import os\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "%time !python3 source/download-guanco-ds.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "481e3945",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "481e3945",
        "outputId": "d9ed5f9e-a3f9-4ea5-c176-880328cb81a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 21M\n",
            "drwxr-xr-x 2 root root 4.0K Jul  2 07:28 .\n",
            "drwxr-xr-x 1 root root 4.0K Jul  2 07:26 ..\n",
            "-rw-r--r-- 1 root root 1.1M Feb 12  2024 openassistant_best_replies_eval.jsonl\n",
            "-rw-r--r-- 1 root root  20M Feb 12  2024 openassistant_best_replies_train.jsonl\n"
          ]
        }
      ],
      "source": [
        "!ls -alh data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8b89fea",
      "metadata": {
        "id": "c8b89fea"
      },
      "source": [
        "**Expected Output:**\n",
        "```python\n",
        "data:\n",
        "README.md  openassistant_best_replies_eval.jsonl   simple_data.json\n",
        "filtered   openassistant_best_replies_train.jsonl\n",
        "...\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e4d841",
      "metadata": {
        "id": "55e4d841"
      },
      "source": [
        "Import all required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d15452bd",
      "metadata": {
        "id": "d15452bd"
      },
      "outputs": [],
      "source": [
        "# In some cases where you have access to limited computing resources, you might have to uncomment os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\" if you run into not enough memory issue\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from langdetect import detect\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "import re\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d359e189",
      "metadata": {
        "id": "d359e189"
      },
      "source": [
        "### Data Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc638ce2",
      "metadata": {
        "id": "dc638ce2"
      },
      "source": [
        "Let's execute the `read_jsonl` function below to read the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7a8ebbfb",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "7a8ebbfb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_jsonl(file_path):\n",
        "    with open(file_path) as f:\n",
        "        data = [json.loads(line) for line in f]\n",
        "        return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae44f18",
      "metadata": {
        "id": "bae44f18"
      },
      "source": [
        "Let's perform the following steps in the cell below:\n",
        "- Set the path to the train and test jsonl files\n",
        "- Read both files using the `read_jsonl` function\n",
        "- Extract 5k samples from the training set\n",
        "- Display the samples to see the content and format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "c4d916a3",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4d916a3",
        "outputId": "47bc7802-5a3f-4561-e815-bbe93391172b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of traning samples:  5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'},\n",
              " {'text': '### Human: ¿CUales son las etapas del desarrollo y en qué consisten según Piaget?### Assistant: Jean Piaget fue un psicólogo suizo que propuso una teoría sobre el desarrollo cognitivo humano que consta de cuatro etapas:\\n\\nEtapa sensoriomotora (0-2 años): Durante esta etapa, el niño aprende a través de sus sentidos y movimientos. Descubre que sus acciones pueden tener un impacto en el entorno y comienza a formarse una idea básica de objetividad y continuidad.\\n\\nEtapa preoperatoria (2-7 años): En esta etapa, el niño comienza a desarrollar un pensamiento simbólico y a comprender que las cosas pueden representar a otras cosas. También comienzan a desarrollar un pensamiento lógico y a comprender conceptos como la causa y el efecto.\\n\\nEtapa de operaciones concretas (7-12 años): Durante esta etapa, el niño desarrolla un pensamiento lógico y comprende las relaciones causales. Empiezan a comprender que las cosas pueden tener múltiples perspectivas y que los conceptos pueden ser más complejos de lo que parecen a simple vista.\\n\\nEtapa de operaciones formales (12 años en adelante): En esta etapa, el individuo desarrolla un pensamiento abstracto y puede comprender conceptos complejos y abstractos. Son capaces de razonar hipotéticamente y tienen la capacidad de reflexionar sobre su propio pensamiento.\\n\\nEstas etapas no son lineales y algunos individuos pueden avanzar en una etapa más rápidamente que en otras. La teoría de Piaget sobre el desarrollo cognitivo ha sido ampliamente utilizada y es una base importante para la investigación y el entendimiento del desarrollo humano.### Human: ¿Hay otras teorías sobre las etapas del desarrollo que reafirmen o contradigan a la teoría de Piaget?'},\n",
              " {'text': '### Human: Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?### Assistant: Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in.\\n\\nThe point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart.\\n\\nThis method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.### Human: I didn\\'t understand how pulling and pushing works. What are we pulling or pushing? And how does it work in terms of code or maths?### Assistant: It has to do with a process called differentiation, which means finding a derivative: a function that tells us whether another function is going up or down at a given point. For example, the derivative of `f(x) = x` is `f\\'(x) = 1`, because it\\'s always going up at a 1:1 ratio. This can be done for a variety of functions; notably, if you know the derivatives of `f(x)` and `g(x)`, you can also get the derivative of `f(g(x))` using a formula called the chain rule. Neural networks happen to be made of differentiable functions, so we can take the derivative of parts or all of it.\\n\\nTo use this for \"pushing\" and \"pulling\", we\\'ll put two images through the neural network. Let\\'s say the images are of a cat and a dog, so we want to increase the distance between the two. We pick one neuron weight from the network and make it a variable `x`, then construct a function that calculates the output of the network based on it and all the other parameters; let\\'s call it `N(x)`. The distance between the cat and dog outputs would be `f(x) = N(cat) - N(dog)`. (Of course, the real output would have more than 1 dimension, but we\\'re simplifying.) We now want to nudge the weight such that it moves the two outputs slightly further apart. For that, we can simply take the derivative! If `f\\'(x)` is positive, that means that increasing the weight will move them further apart, so we should do that. If it\\'s negative, then it\\'ll move them closer, so we\\'ll want to slightly decrease the weight instead. Apply this to all the neurons enough times and your network will soon converge to a pretty good cat-dog separator!'},\n",
              " {'text': \"### Human: I want to start doing astrophotography as a hobby, any suggestions what could i do?### Assistant: Getting started in astrophotography can seem daunting, but with some patience and practice, you can become a master of the craft. To begin, you'll need a good camera and lens, a tripod, and a dark sky location free of light pollution. You will also need to learn about the basics of astrophotography, such as what camera settings to use, how to capture star trails, and the best techniques for tracking celestial objects. You can also purchase or rent different types of telescopes, depending on what types of objects you want to capture. Additionally, it's important to keep up with the latest astrophotography news and trends. Once you have the necessary equipment and knowledge, you can start shooting and experimenting with different techniques to get the best results.### Human: Can you tell me more?  What would you recommend as a basic set of equipment to get started with?  How much will it cost?### Assistant: Astrophotography can be a fun and rewarding hobby, and here are some more in depth suggestions for you to get started:\\n\\n    Equipment: As a beginner, you will need a camera that is capable of taking long exposures and manual control over the settings. A good starting point would be a digital SLR (DSLR) camera or a mirrorless camera. You will also need a sturdy tripod, a fast wide-angle lens (f/2.8 or faster), and a remote shutter release cable to minimize camera shake during long exposures.\\n\\n    Location: Look for a location with minimal light pollution and a clear view of the night sky. Check online maps to find the best spots near you.\\n\\n    Settings: Start with a wide-angle lens and set your camera to manual mode. Set your aperture to f/2.8 or wider, ISO to 800 or 1600, and experiment with different exposure times (30 seconds to 2 minutes).\\n\\n    Focus: Focus the lens on the stars using live view and manual focus. You may also need to use a Bahtinov mask to achieve accurate focus.\\n\\n    Editing: After you've taken your photos, use editing software such as Adobe Lightroom or Photoshop to adjust the exposure, contrast, and color balance to get the best results.\\n\\nThe cost of equipment will depend on the type of camera and lens you choose, but a basic setup can cost anywhere from $500 to $3000. However, you don't need to start with the most expensive equipment to get good results. As you improve, you can upgrade your equipment and add additional accessories such as filters and tracking mounts.\\n\\nRemember, astrophotography is a hobby that requires patience and practice, so don't be discouraged if your first few attempts don't turn out as well as you had hoped. Keep experimenting and learning, and you'll soon be able to capture stunning images of the night sky!### Human: What is a good course of instruction to avoid years of wasted effort?\"},\n",
              " {'text': '### Human: Método del Perceptrón biclásico: definición y variantes del método. ¿cómo se aplicaría\\nal caso multiclásico?, ¿se podría utilizar con patrones que sólo son cuadráticamente\\nseparables?### Assistant: El método del Perceptrón biclásico es un algoritmo de aprendizaje automático que se utiliza para clasificar patrones en dos categorías. El objetivo del Perceptrón es encontrar un hiperplano que separe las dos clases en el espacio de características.\\n\\nEn el Perceptrón biclásico, se utilizan los siguientes pasos para entrenar el modelo:\\n\\n1. Inicializar los pesos con valores aleatorios.\\n2. Seleccionar un patrón aleatorio del conjunto de entrenamiento y calcular la salida del Perceptrón.\\n3. Actualizar los pesos si la salida del Perceptrón es incorrecta.\\n4. Repetir los pasos 2 y 3 hasta que se alcance un criterio de parada.\\n\\nHay varias variantes del método del Perceptrón biclásico, incluyendo el Perceptrón con margen, el Perceptrón promedio, el Perceptrón relajado y el Perceptrón de múltiples capas.\\n\\nEn el caso multiclase, se puede utilizar una variante del Perceptrón biclásico conocida como Perceptrón multicapa, que utiliza varias capas de neuronas para clasificar patrones en múltiples categorías. Cada capa se encarga de realizar una transformación no lineal de los datos de entrada y de propagar la información a la siguiente capa hasta llegar a la capa de salida, donde se realiza la clasificación.\\n\\nEn cuanto a si se puede utilizar el Perceptrón biclásico con patrones que sólo son cuadráticamente separables, la respuesta es que no. El Perceptrón biclásico sólo puede separar patrones linealmente separables. Para patrones cuadráticamente separables se pueden utilizar otros algoritmos de clasificación como SVM, regresión logística, árboles de decisión, entre otros.'},\n",
              " {'text': '### Human: Schreibe einen kurze und präzise Konstruktionsbeschreibung zu einem Dreieck ABC mit c=6\\xa0cm, h_c=5\\xa0cm und γ=40°. γ ist hierbei der von Seite c gegenüberliegende Winkel.### Assistant: Dreieck ABC ist ein rechtwinkliges Dreieck mit der Seitenlänge c=6 cm als Hypotenuse. Die Höhe h_c von c beträgt 5 cm und der Winkel γ von c gegenüberliegend beträgt 40°.### Human: Vielen Dank, das hat mir sehr weitergeholfen.'},\n",
              " {'text': '### Human: Can you give me an example of a python script that opens an api point and serves a string?### Assistant: Sure! Here\\'s an example Python script that uses the Flask web framework to create a simple API endpoint that serves a string:\\n\\n``` \\nfrom flask import Flask\\n\\napp = Flask(__name__)\\n\\n@app.route(\\'/\\')\\ndef hello_world():\\n    return \\'Hello, world!\\'\\n\\nif __name__ == \\'__main__\\':\\n    app.run()\\n\\n``` \\n\\nIn this script, we first import the Flask class from the flask module. Then we create a new instance of the Flask class, using the __name__ variable to specify the name of the application.\\n\\\\\\nNext, we define a new route using the @app.route() decorator. This decorator tells Flask to map requests to the root URL (\"/\") to the hello_world() function.\\n\\\\\\nFinally, we use the if __name__ == \\'__main__\\': block to start the Flask application when the script is executed. By default, the application will run on port 5000.\\n\\\\\\nYou can run this script and test the API by opening a web browser and navigating to http://localhost:5000/. You should see a simple \"Hello, world!\" message displayed in your browser.### Human: What changes would you need to make to the code above to serve a JSON object instead of a string?### Assistant: To serve a JSON object instead of a string, you can modify the \"hello_world()\" function to return a JSON response using the Flask \"jsonify\" function. Here\\'s an example of how to modify the previous code to serve a JSON object:\\n\\n```\\nfrom flask import Flask, jsonify\\n\\napp = Flask(name)\\n\\n@app.route(\\'/\\')\\ndef hello_world():\\ndata = {\\n\\'message\\': \\'Hello, world!\\'\\n}\\nreturn jsonify(data)\\n\\nif name == \\'main\\':\\napp.run()\\n```\\n\\nIn this updated version of the code, we import the \"jsonify\" function from Flask and use it to create a JSON response. We define a dictionary called \"data\" that contains a single key-value pair, where the key is \"message\" and the value is \"Hello, world!\".\\n\\nThe \"jsonify\" function takes a dictionary as its argument and returns a JSON-formatted response with the appropriate content-type headers. When we visit the root URL of our Flask application, we will see a JSON object with the \"message\" key and its associated value.\\n\\nYou can test this modified script in the same way as the previous example, by opening a web browser and navigating to http://localhost:5000/. This time, you should see a JSON object with the \"message\" key and its associated value displayed in your browser.'},\n",
              " {'text': \"### Human: How can I learn to optimize my webpage for search engines?### Assistant: Learning to optimize your webpage for search engines involves several steps, including:\\n\\n1. Understanding the basics of how search engines work: Learn how search engines crawl and index web pages, and how they rank pages based on factors like relevance, authority, and user experience.\\n2. Conducting keyword research: Identify the keywords and phrases that your target audience is using to search for your products or services, and use these keywords to optimize your web pages.\\n3. Creating high-quality content: Create content that is informative, engaging, and relevant to your target audience. This can include blog posts, articles, videos, and other types of content.\\n4. Optimizing your web pages: Optimize your page titles, meta descriptions, header tags, and other on-page elements to make sure they are aligned with your target keywords and provide a clear picture of what your page is about.\\n5. Building backlinks: Build high-quality backlinks from other reputable websites to your own site. This can help increase your authority and improve your search engine rankings.\\n6. Monitoring your results: Use analytics tools to track your website's performance in search engine rankings, and adjust your strategy as needed based on your results.\\n\\nThere are many resources available online to help you learn more about search engine optimization (SEO), including blogs, courses, and tutorials. Some popular SEO resources include Moz, SEMrush, and Google's Search Console documentation.\\n\\nIt's important to note that SEO is an ongoing process, and it can take time and effort to see results. However, by following best practices and staying up-to-date with the latest trends and techniques, you can help improve your website's visibility and attract more traffic from search engines.### Human: My webpage is about flower arrangements. Can you give some examples for each of the above?\"},\n",
              " {'text': '### Human: Напиши информацию о игре Hytale### Assistant: Hytale - это предстоящая игра-песочница, придуманная Hypixel Studios. Объединяя в себе диапазон игры-песочницы с глубиной ролевой игры, Hytale погружает игроков в живой космос, полный эскапад и творчества.\\n\\nВ Hytale геймеры могут путешествовать по просторному, процедурно созданному миру и принимать участие в разнообразных действиях. От возведения баз и создания собственных персонажей до создания карт приключений и сражений с монстрами или другими игроками - возможности Hytale безграничны. Игроки также могут создавать свои собственные серверы, которые можно использовать совместно с другими геймерами, что позволяет создавать необычные сообщества.\\n\\nВ игре также имеется обширная система моддинга, позволяющая игрокам создавать и делиться своими собственными предметами. С помощью системы моддинга геймеры могут создавать пользовательское оружие, броню и другие предметы, а также пользовательские карты и режимы игры. Эта функция позволяет игрокам создавать свои собственные необычные впечатления и делиться ими с друзьями и другими игроками.\\n\\nИгра также отличается роскошным саундтреком и впечатляющими визуальными эффектами, а разнообразие окружения варьируется от роскошных лесов до засушливых пустынь. В Hytale также имеется обширная система настройки персонажей, позволяющая геймерам создавать собственных героев, настраивать их наряды и выбирать собственный стиль игры.\\n\\nВ целом, Hytale - это энергичная предстоящая игра, которая обещает предложить необычный и захватывающий опыт. Благодаря обширному миру, разнообразным действиям, системе моддинга, захватывающему саундтреку и визуальному оформлению, Hytale обещает стать увлекательной игрой, которая завладеет сердцами и воображением геймеров по всей вселенной.### Human: Ты бы мог в неё играть?'},\n",
              " {'text': '### Human: Estoy pensando en crear un videojuego pero no estoy seguro de que motor de juego quiero utilizar. Al buscar por internet me parece que hay muchos opciones buenas.\\nQuiero crear un juego online en tiempo real. Será un shooter en tercera persona con la cámara al hombro.\\nEl nivel de gráficos que busco no es demasiado alto pero tampoco bajo. Los gráficos serán algo estilizados.\\nTengo estudios de informática así que aprender cualquier lenguaje de programación no es un problema demasiado grande.\\n¿Me puedes dar algunas recomendaciones de motores para mi videojuegos?\\n¿Podrías compararlos entre ellos y darme unos pros y contras?### Assistant: ¡Claro! Hay varios motores de juego que podrían ser adecuados para tu proyecto, cada uno con sus propias ventajas y desventajas. A continuación, te daré una comparación de los motores de juego más populares y te explicaré sus pros y contras.\\n\\n1. Unreal Engine:\\nEl Unreal Engine es uno de los motores de juego más populares en el mercado, especialmente en lo que respecta a los juegos de disparos en tercera persona. Es muy conocido por su capacidad para crear gráficos de alta calidad y su comunidad de usuarios muy activa. Es fácil de usar y viene con muchas características útiles como herramientas de nivel de editor y animación. Además, también es gratuito.\\nPros: Fácil de usar, gráficos de alta calidad, buena documentación, gran comunidad de usuarios.\\n\\nContras: Puede ser complicado para principiantes, requiere una PC de gama alta para funcionar bien, tiene una curva de aprendizaje pronunciada.\\n\\n2. Unity:\\nUnity es otro popular motor de juego para el desarrollo de juegos en tercera persona. Es conocido por su facilidad de uso y su capacidad para crear juegos para múltiples plataformas, incluyendo PC, móvil y consolas. Unity también es gratuito y tiene una gran comunidad de usuarios.\\nPros: Fácil de usar, funciona en múltiples plataformas, buena documentación, gran comunidad de usuarios.\\n\\nContras: Los gráficos pueden no ser tan impresionantes como los de Unreal Engine, puede ser difícil para los desarrolladores novatos, requiere una suscripción para ciertas características avanzadas.\\n\\n3. CryEngine:\\nCryEngine es un motor de juego popular para el desarrollo de juegos en tercera persona que es conocido por sus gráficos impresionantes y su capacidad para crear entornos enormes y detallados. Es utilizado por muchos estudios de juegos AAA y es conocido por su alta calidad visual.\\nPros: Gráficos impresionantes, gran capacidad para entornos detallados, buena documentación.\\n\\nContras: Puede ser difícil para los desarrolladores novatos, requiere una PC de gama alta para funcionar bien, tiene una curva de aprendizaje pronunciada.\\n\\n4. Godot:\\nGodot es un motor de juego gratuito y de código abierto que es fácil de usar y tiene una gran comunidad de usuarios. Es conocido por su capacidad para crear juegos 2D y 3D, y es especialmente adecuado para proyectos más pequeños. Godot tiene una curva de aprendizaje más suave que otros motores y es muy personalizable.\\nPros: Fácil de usar, gratuito y de código abierto, gran capacidad para personalizar, buena documentación.\\n\\nContras: No es tan potente como otros motores de juego, puede ser más adecuado para proyectos más pequeños, los gráficos pueden no ser tan impresionantes.\\n\\nEn resumen, los cuatro motores de juego mencionados son excelentes opciones para el desarrollo de un shooter en tercera persona. Cada uno tiene sus propias ventajas y desventajas, por lo que la elección dependerá de tus necesidades específicas y habilidades. Si estás buscando gráficos impresionantes, Unreal Engine y CryEngine son excelentes opciones. Si prefieres una opción más fácil de usar, Unity y Godot podrían ser una mejor opción.### Human: Podrías generar una tabla comparativa con todos los motores de juego que mencionaste?. Dicha tabla también debe contener algunos títulos de juegos hechos usando dicho motor.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#set path to jsonl files\n",
        "train_path = '/content/data/openassistant_best_replies_train.jsonl'\n",
        "test_path = '/content/data/openassistant_best_replies_eval.jsonl'\n",
        "\n",
        "# read the files\n",
        "raw_train_data = read_jsonl(train_path)\n",
        "raw_test_data = read_jsonl(test_path)\n",
        "\n",
        "# extract 5000 samples\n",
        "train_samples = raw_train_data[:5000]\n",
        "\n",
        "print(\"length of traning samples: \", len(train_samples))\n",
        "train_samples[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "abed0cf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abed0cf4",
        "outputId": "16db3a37-bcae-4f98-9405-f0b98dc5ee28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9846 5000\n"
          ]
        }
      ],
      "source": [
        "print( len(raw_train_data), len(train_samples) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ddb8d26",
      "metadata": {
        "id": "6ddb8d26"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "\n",
        "length of traning samples:  5000\n",
        "[{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as ..'},\n",
        " ...\n",
        " {'text': '### Human: ¿CUales son las etapas del desarrollo y en qué consisten según Piaget?### Assistant: Jean Piaget fue un psicólogo suizo que propuso una teoría sobre el desarrollo cognitivo humano que consta de cuatro etapas:\\n\\nEtapa sensoriomotora (0-2 años): Durante esta etapa, el niño aprende a través de sus sentidos y movimientos. Descubre que sus acciones pueden tener un impacto en el entorno y comienza a formarse una idea básica de objetividad y continuidad.\\n\\nEtapa preoperatoria (2-7 años): En esta etapa, el niño comienza a desarrollar un pensamiento simbólico y a comprender que las cosas pueden representar a otras cosas. También comienzan a desarrollar un pensamiento lógico y a comprender conceptos como la causa y el efecto.\\n\\nEtapa de ...?'},\n",
        " ...\n",
        " {'text': '### Human: Schreibe einen kurze und präzise Konstruktionsbeschreibung zu einem Dreieck ABC mit c=6\\xa0cm, h_c=5\\xa0cm und γ=40°. γ ist hierbei der von Seite c gegenüberliegende Winkel.### Assistant: Dreieck ABC ist ein rechtwinkliges Dreieck mit der Seitenlänge c=6 cm als Hypotenuse. Die Höhe h_c von c beträgt 5 cm und der Winkel γ von c gegenüberliegend beträgt 40°.### Human: Vielen Dank, das hat mir sehr weitergeholfen.'},\n",
        " {'text': '### Human: Напиши информацию о игре Hytale### Assistant: Hytale - это предстоящая игра-песочница, придуманная Hypixel Studios. Объединяя в себе диапазон игры-песочницы с глубиной ролевой игры, Hytale погружает игроков в живой космос, полный эскапад и творчества.\\n\\nВ Hytale геймеры могут путешествовать по просторному, процедурно созданному миру и принимать участие в разнообразных действиях. От возведения баз и создания собственных персонажей до создания карт приключений и сражений с монстрами или другими игроками - возможности Hytale безграничны. Игроки также могут создавать свои ..'},\n",
        " {'text': '### Human: 私は猫ちゃんが好きなんですけど\\n貴方も猫ちゃんが好きですか?### Assistant: 猫ちゃんが好きなんですね。\\n私も猫ちゃんが好きですよ！\\n猫ちゃんのどんなところが好きですか？### Human: 猫ちゃんの全てが好きです！猫ちゃんは天使です！！### Assistant: わかりますよ、その気持ち！\\n猫ちゃんの愛くるしい姿は、天使みたいに可愛いですよね！\\nあなたのお家に、猫ちゃんはいるんですか？### Human: 勿論です！とっても可愛くて、毎日が幸せです！'},\n",
        "\n",
        " {'text': \"### Human: Quins sinònims amb altres dialectes d'aquesta llengua té nen o nena?### Assistant: Al·lot o al·lota, vailet o vaileta, manyac o manyaga, nin o nina, xiquet o xiqueta, xic o xica, marrec, minyó o minyona.\"},\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d6db58",
      "metadata": {
        "id": "b6d6db58"
      },
      "source": [
        "We can see from the content displayed that the file contains text written in different languages. For demonstration purposes, we want to consider only English text for training and prompting. Therefore, the train and test sets will be processed to filter out non-English text samples using a `detect` feature from the `spacy-langdetect` library. The English-only texts (`1778 training samples`) are saved as the new training set. The same process is applied to the test samples. Run the three two cells below to execute the filter process.     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "12cbfaf8",
      "metadata": {
        "id": "12cbfaf8"
      },
      "outputs": [],
      "source": [
        "# filter non-Emglish word\n",
        "def remove_nonEnglish_rows(ds):\n",
        "    new_ds = []\n",
        "    for row in (ds):\n",
        "        if detect(str(row)) == 'en':\n",
        "            new_ds.append(row)\n",
        "    return new_ds\n",
        "\n",
        "# save English text samples\n",
        "os.makedirs(\"/content/data/filtered\", exist_ok=True)\n",
        "\n",
        "def save_jsonl(ds,filename):\n",
        "    with open(f\"/content/data/filtered/{filename}.jsonl\", \"w\") as write_file:\n",
        "            json.dump(ds, write_file, indent=4)\n",
        "            print(\"dataset saved in jsonl format ....\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "93f7da81",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93f7da81",
        "outputId": "ea2eba2f-2769-4f7d-d1f3-052c07246e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len of training samples:  1778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'},\n",
              " {'text': '### Human: Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?### Assistant: Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and a dog picture could have very similar representations (their numbers would be close to each other), while at others two cat images may be represented far apart. In simple terms, the model wouldn\\'t be able to tell cats and dogs apart. This is where contrastive learning comes in.\\n\\nThe point of contrastive learning is to take pairs of samples (in this case images of cats and dogs), then train the model to \"pull\" representations of similar pairs (cat-cat or dog-dog) closer to each other and \"push\" representations of different pairs (cat-dog) apart. After doing this for a sufficient number of steps, your model will be able to produce unique, reliable representations for cats and dogs, in essence tell them apart.\\n\\nThis method is not limited to images, you can typically use it with any dataset that has similar and dissimilar data points.### Human: I didn\\'t understand how pulling and pushing works. What are we pulling or pushing? And how does it work in terms of code or maths?### Assistant: It has to do with a process called differentiation, which means finding a derivative: a function that tells us whether another function is going up or down at a given point. For example, the derivative of `f(x) = x` is `f\\'(x) = 1`, because it\\'s always going up at a 1:1 ratio. This can be done for a variety of functions; notably, if you know the derivatives of `f(x)` and `g(x)`, you can also get the derivative of `f(g(x))` using a formula called the chain rule. Neural networks happen to be made of differentiable functions, so we can take the derivative of parts or all of it.\\n\\nTo use this for \"pushing\" and \"pulling\", we\\'ll put two images through the neural network. Let\\'s say the images are of a cat and a dog, so we want to increase the distance between the two. We pick one neuron weight from the network and make it a variable `x`, then construct a function that calculates the output of the network based on it and all the other parameters; let\\'s call it `N(x)`. The distance between the cat and dog outputs would be `f(x) = N(cat) - N(dog)`. (Of course, the real output would have more than 1 dimension, but we\\'re simplifying.) We now want to nudge the weight such that it moves the two outputs slightly further apart. For that, we can simply take the derivative! If `f\\'(x)` is positive, that means that increasing the weight will move them further apart, so we should do that. If it\\'s negative, then it\\'ll move them closer, so we\\'ll want to slightly decrease the weight instead. Apply this to all the neurons enough times and your network will soon converge to a pretty good cat-dog separator!'},\n",
              " {'text': \"### Human: I want to start doing astrophotography as a hobby, any suggestions what could i do?### Assistant: Getting started in astrophotography can seem daunting, but with some patience and practice, you can become a master of the craft. To begin, you'll need a good camera and lens, a tripod, and a dark sky location free of light pollution. You will also need to learn about the basics of astrophotography, such as what camera settings to use, how to capture star trails, and the best techniques for tracking celestial objects. You can also purchase or rent different types of telescopes, depending on what types of objects you want to capture. Additionally, it's important to keep up with the latest astrophotography news and trends. Once you have the necessary equipment and knowledge, you can start shooting and experimenting with different techniques to get the best results.### Human: Can you tell me more?  What would you recommend as a basic set of equipment to get started with?  How much will it cost?### Assistant: Astrophotography can be a fun and rewarding hobby, and here are some more in depth suggestions for you to get started:\\n\\n    Equipment: As a beginner, you will need a camera that is capable of taking long exposures and manual control over the settings. A good starting point would be a digital SLR (DSLR) camera or a mirrorless camera. You will also need a sturdy tripod, a fast wide-angle lens (f/2.8 or faster), and a remote shutter release cable to minimize camera shake during long exposures.\\n\\n    Location: Look for a location with minimal light pollution and a clear view of the night sky. Check online maps to find the best spots near you.\\n\\n    Settings: Start with a wide-angle lens and set your camera to manual mode. Set your aperture to f/2.8 or wider, ISO to 800 or 1600, and experiment with different exposure times (30 seconds to 2 minutes).\\n\\n    Focus: Focus the lens on the stars using live view and manual focus. You may also need to use a Bahtinov mask to achieve accurate focus.\\n\\n    Editing: After you've taken your photos, use editing software such as Adobe Lightroom or Photoshop to adjust the exposure, contrast, and color balance to get the best results.\\n\\nThe cost of equipment will depend on the type of camera and lens you choose, but a basic setup can cost anywhere from $500 to $3000. However, you don't need to start with the most expensive equipment to get good results. As you improve, you can upgrade your equipment and add additional accessories such as filters and tracking mounts.\\n\\nRemember, astrophotography is a hobby that requires patience and practice, so don't be discouraged if your first few attempts don't turn out as well as you had hoped. Keep experimenting and learning, and you'll soon be able to capture stunning images of the night sky!### Human: What is a good course of instruction to avoid years of wasted effort?\"},\n",
              " {'text': '### Human: Can you give me an example of a python script that opens an api point and serves a string?### Assistant: Sure! Here\\'s an example Python script that uses the Flask web framework to create a simple API endpoint that serves a string:\\n\\n``` \\nfrom flask import Flask\\n\\napp = Flask(__name__)\\n\\n@app.route(\\'/\\')\\ndef hello_world():\\n    return \\'Hello, world!\\'\\n\\nif __name__ == \\'__main__\\':\\n    app.run()\\n\\n``` \\n\\nIn this script, we first import the Flask class from the flask module. Then we create a new instance of the Flask class, using the __name__ variable to specify the name of the application.\\n\\\\\\nNext, we define a new route using the @app.route() decorator. This decorator tells Flask to map requests to the root URL (\"/\") to the hello_world() function.\\n\\\\\\nFinally, we use the if __name__ == \\'__main__\\': block to start the Flask application when the script is executed. By default, the application will run on port 5000.\\n\\\\\\nYou can run this script and test the API by opening a web browser and navigating to http://localhost:5000/. You should see a simple \"Hello, world!\" message displayed in your browser.### Human: What changes would you need to make to the code above to serve a JSON object instead of a string?### Assistant: To serve a JSON object instead of a string, you can modify the \"hello_world()\" function to return a JSON response using the Flask \"jsonify\" function. Here\\'s an example of how to modify the previous code to serve a JSON object:\\n\\n```\\nfrom flask import Flask, jsonify\\n\\napp = Flask(name)\\n\\n@app.route(\\'/\\')\\ndef hello_world():\\ndata = {\\n\\'message\\': \\'Hello, world!\\'\\n}\\nreturn jsonify(data)\\n\\nif name == \\'main\\':\\napp.run()\\n```\\n\\nIn this updated version of the code, we import the \"jsonify\" function from Flask and use it to create a JSON response. We define a dictionary called \"data\" that contains a single key-value pair, where the key is \"message\" and the value is \"Hello, world!\".\\n\\nThe \"jsonify\" function takes a dictionary as its argument and returns a JSON-formatted response with the appropriate content-type headers. When we visit the root URL of our Flask application, we will see a JSON object with the \"message\" key and its associated value.\\n\\nYou can test this modified script in the same way as the previous example, by opening a web browser and navigating to http://localhost:5000/. This time, you should see a JSON object with the \"message\" key and its associated value displayed in your browser.'},\n",
              " {'text': \"### Human: How can I learn to optimize my webpage for search engines?### Assistant: Learning to optimize your webpage for search engines involves several steps, including:\\n\\n1. Understanding the basics of how search engines work: Learn how search engines crawl and index web pages, and how they rank pages based on factors like relevance, authority, and user experience.\\n2. Conducting keyword research: Identify the keywords and phrases that your target audience is using to search for your products or services, and use these keywords to optimize your web pages.\\n3. Creating high-quality content: Create content that is informative, engaging, and relevant to your target audience. This can include blog posts, articles, videos, and other types of content.\\n4. Optimizing your web pages: Optimize your page titles, meta descriptions, header tags, and other on-page elements to make sure they are aligned with your target keywords and provide a clear picture of what your page is about.\\n5. Building backlinks: Build high-quality backlinks from other reputable websites to your own site. This can help increase your authority and improve your search engine rankings.\\n6. Monitoring your results: Use analytics tools to track your website's performance in search engine rankings, and adjust your strategy as needed based on your results.\\n\\nThere are many resources available online to help you learn more about search engine optimization (SEO), including blogs, courses, and tutorials. Some popular SEO resources include Moz, SEMrush, and Google's Search Console documentation.\\n\\nIt's important to note that SEO is an ongoing process, and it can take time and effort to see results. However, by following best practices and staying up-to-date with the latest trends and techniques, you can help improve your website's visibility and attract more traffic from search engines.### Human: My webpage is about flower arrangements. Can you give some examples for each of the above?\"},\n",
              " {'text': '### Human: Listened to Dvorak\\'s \"The New World\" symphony, liked it much. What composers, not necessarily from Dvorak\\'s time, wrote similar music? Provide a few suggestions, give composer names and their respective works. Also, what Dvorak\\'s other works sound like the \"New World\"?### Assistant: If you enjoyed Dvorak\\'s \"New World\" Symphony, here are a few other composers and works you might enjoy:\\n\\n1. Pyotr Ilyich Tchaikovsky - Symphony No. 5 in E minor, Op. 64\\n2. Jean Sibelius - Symphony No. 2 in D major, Op. 43\\n3. Aaron Copland - Appalachian Spring\\n4. Edward Elgar - Enigma Variations, Op. 36\\n5. Gustav Mahler - Symphony No. 1 in D major, \"Titan\"\\n6. Samuel Barber - Adagio for Strings\\n\\nRegarding other works by Dvorak that have similar musical characteristics to the \"New World\" Symphony, here are some suggestions:\\n\\n1. Dvorak - Symphony No. 8 in G major, Op. 88\\n2. Dvorak - String Quartet No. 12 in F major, Op. 96 \"American\"\\n3. Dvorak - Symphony No. 7 in D minor, Op. 70\\n4. Dvorak - Symphony No. 6 in D major, Op. 60\\n\\nThese works all contain elements of Dvorak\\'s folk-inspired melodies, lush orchestration, and memorable themes that you may have enjoyed in the \"New World\" Symphony.'},\n",
              " {'text': \"### Human: I am using docker compose and i need to mount the docker socket - how would i do that?### Assistant: You can mount the Docker socket in a Docker Compose service by adding the following to your docker-compose.yml file:\\n\\njavascript\\n\\nversion: '3'\\nservices:\\n  your_service_name:\\n    # ... other service configuration\\n    volumes:\\n      - /var/run/docker.sock:/var/run/docker.sock\\n\\nThis will mount the host's Docker socket at /var/run/docker.sock inside the service's container. This allows the service to interact with the host's Docker daemon and perform tasks such as starting and stopping containers.\\n\\nIt is important to note that mounting the Docker socket inside a container can potentially expose your host to security risks, so it should only be done in trusted environments or with proper security measures in place.\"},\n",
              " {'text': '### Human: I\\'m creating a NodeJS backend using Express, and I\\'m getting the following error:\\n`Uncaught TypeError: Cannot read properties of undefined (reading \\'id\\')`\\n\\nMy code of where this error is happening is as follows:\\n```\\napp.delete(\\'/post\\', (req, res) => {\\n    const user = getUser(req.user.user_id);\\n    if (!user) return res.sendStatus(401);\\n    const post = getPost(req.body.id);\\n    if (!post) return res.sendStatus(404);\\n    if (post.user_id != req.user.user_id) return res.sendStatus(403);\\n    // Code that deletes the post through DB\\n    return res.sendStatus(201);\\n});\\n```\\n\\nWhat are ways I can fix this error?### Assistant: The error \"Uncaught TypeError: Cannot read properties of undefined (reading \\'id\\')\" is likely occurring because \"req.body.id\" is undefined. To resolve this error, you should add a check to verify that \"req.body.id\" exists before trying to access its properties.\\n\\nYou can do this by adding a conditional statement before accessing \"req.body.id\":\\n\\n\\'\\'\\'\\napp.delete(\\'/post\\', (req, res) => {\\n    const user = getUser(req.user.user_id);\\n    if (!user) return res.sendStatus(401);\\n    if (!req.body.id) return res.sendStatus(400);\\n    const post = getPost(req.body.id);\\n    if (!post) return res.sendStatus(404);\\n    if (post.user_id != req.user.user_id) return res.sendStatus(403);\\n    // Code that deletes the post through DB\\n    return res.sendStatus(201);\\n});\\n\\'\\'\\'\\n\\nThis way, if req.body.id is undefined, the code will return a status of 400 Bad Request instead of attempting to access undefined properties.### Human: Thank you that was very helpful!### Assistant: You\\'re welcome. As an AI assistant, I do my best to help you however I can.'},\n",
              " {'text': \"### Human: Write a 4chan style greentext about someone who loves the new romantic comedy movie, with an ironic twist that re-contextualizes the story at the end.. It should start with '>be me'### Assistant: >be me\\n>sister wants to watch the new hit romcom\\n>not a fan, but what the hell, its got a fantasy theme\\n>we're watching, but a sex scene comes up\\n>then another\\n>i keep looking away from the screen\\n>lotsofsex.jpg\\n>sister starts teasing me for my discomfort \\n\\nSo anyway, how did you get into Game of Thrones?\"},\n",
              " {'text': '### Human: How would I create a script for blender that replaces all of objects with a specific name with a point light?### Assistant: Here\\'s an example Python script for Blender that replaces all objects with a specific name (in this case, \"Cube\") with a point light:\\n\\n```\\npython\\n\\nimport bpy\\n\\n# Set the name of the object you want to replace\\nobject_name = \"Cube\"\\n\\n# Create a new point light\\nlight_data = bpy.data.lights.new(name=\"Point Light\", type=\"POINT\")\\nlight_object = bpy.data.objects.new(name=\"Point Light\", object_data=light_data)\\nbpy.context.scene.collection.objects.link(light_object)\\n\\n# Find all objects with the specified name and replace them with the point light\\nfor obj in bpy.context.scene.objects:\\n    if obj.name.startswith(object_name):\\n        obj_index = obj.pass_index # store the original index of the object for later use\\n        obj_data = obj.data\\n        obj_matrix = obj.matrix_world\\n        bpy.data.objects.remove(obj)\\n        light_object.pass_index = obj_index # assign the original index to the new object\\n        light_object.matrix_world = obj_matrix\\n        light_object.data = light_data\\n```\\n\\nTo use this script, open Blender and create or open a file with objects named \"Cube\". Then, go to the Scripting workspace and create a new text file. Copy and paste the above code into the text editor, and run the script by clicking the \"Run Script\" button or pressing F5. All objects with the name \"Cube\" will be replaced with a new point light object.### Human: When I run this code in Blender 3.4.1 as you specified it does in fact replace the cube with a point light. Thank you for the helpful code! How could I achieve the same effect but by object type instead of name?'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#calling filter function\n",
        "filter_train_samples = remove_nonEnglish_rows(train_samples)\n",
        "filter_test_samples = remove_nonEnglish_rows(raw_test_data )\n",
        "\n",
        "print(\"len of training samples: \",len(filter_train_samples))\n",
        "filter_train_samples[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "8551c25c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8551c25c",
        "outputId": "95125f51-7afc-483f-88d1-5e8017c24cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9846 5000 1778\n",
            "518 189\n"
          ]
        }
      ],
      "source": [
        "print( len(raw_train_data),  len(train_samples), len(filter_train_samples), )\n",
        "print( len(raw_test_data),   len(filter_test_samples) )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7e2ba7",
      "metadata": {
        "id": "3e7e2ba7"
      },
      "source": [
        "**Expected output:**\n",
        "```python\n",
        "len of training samples:  1775\n",
        "[{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as ...'},\n",
        " {'text': '### Human: Can you explain contrastive learning in machine learning in simple terms for someone new to the field of ML?### Assistant: Sure! Let\\'s say you want to build a model which can distinguish between images of cats and dogs. You gather your dataset, consisting of many cat and dog pictures. Then you put them through a neural net of your choice, which produces some representation for each image, a sequence of numbers like [0.123, 0.045, 0.334, ...]. The problem is, if your model is unfamiliar with cat and dog images, these representations will be quite random. At one time a cat and ...'},\n",
        " {'text': \"### Human: I want to start doing astrophotography as a hobby, any suggestions what could i do?### Assistant: Getting started in astrophotography can seem daunting, but with some patience and practice, you can become a master of the craft. To begin, you'll need a good camera and lens, a tripod, and a dark sky location free of light pollution. You will also need to learn about the basics of astrophotography, such as what camera settings to use, how to capture star trails, and the best techniques for tracking celestial objects. You can also purchase or rent different types of telescopes, depending on what types of objects you want to capture. Additionally, it's important to keep up with the latest astrophotography news and trends. Once you have the necessary ...\"},\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "418ee8f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418ee8f2",
        "outputId": "44bac8dc-c3ac-4ee0-9885-6f16f26843aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset saved in jsonl format ....\n",
            "dataset saved in jsonl format ....\n"
          ]
        }
      ],
      "source": [
        "# set file names\n",
        "save_train_filename = 'train'\n",
        "save_test_filename = 'test'\n",
        "\n",
        "# save file\n",
        "save_jsonl(filter_train_samples, save_train_filename)\n",
        "save_jsonl(filter_test_samples, save_test_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff8eb47",
      "metadata": {
        "tags": [],
        "id": "aff8eb47"
      },
      "source": [
        "### Data Transformation\n",
        "\n",
        "In this section, we want to format our dataset to the Llama2 acceptable template for finetuning:\n",
        "\n",
        "```python\n",
        "\n",
        "<s>[INST] {human text} [/INST] {assistant/context} </s>\n",
        "<s>[INST]{human text} [/INST] </s>\n",
        "\n",
        "```\n",
        "- **Human text**: It denotes human instructions to the model. The human text is enclosed within an instruction tag `[INST] [/INST]`\n",
        "- **Assistant**: represents the context that will assist the model in drawing out a response to the instruction issued by a human. The assistant text is nested to the human text within a segment tag `<s>  </s>`.\n",
        "\n",
        "One or more segments can exist within a training sample text. A segment can consist of both human instruction text and assistant context or human instruction text only.\n",
        "\n",
        "\n",
        "<img src=\"images/template.png\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732c6f34",
      "metadata": {
        "id": "732c6f34"
      },
      "source": [
        "Next, we load the filtered dataset by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "30fb2806",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "37f94484674e4319af71c9c90725f509",
            "f91c8e4a87194f508eb205137ab9588e",
            "aa6a2bc9e6e44c9cafb74388a3440449",
            "d4e4c2fd026d4060a7185d1375c974ff",
            "12156d3ad08e4adba39314e355fb16bc",
            "2c85f9027e9d426998f28ac5ba0e79be",
            "70710f1b8b2240bc95f49a45ce9b7b41",
            "9d21cac2eca64a728874c676889f4fdc",
            "ba6f827cc20a40a187a2a59ed760d593",
            "828aa7a256ad471b8fd76c2ddf6abc91",
            "9ab7e6b00fef4f46bcbb30b547dc7b18",
            "ebfff18534ba4a14ae396820af4ff824",
            "312d649f9530440b81835bc4dd3a03f0",
            "6338b9e90a41471d80e1098560479d4f",
            "a466ef9111d54fe586b9983a020b65ad",
            "b85049b021e540198c986f50eed5f54f",
            "62e16e5d95514cacb284135e4956371e",
            "ee15a4ec0586406c96fcb9b1c1e8c5ef",
            "06767481ea8342a896e53a9bb91d044d",
            "47a394afd2284257b2f67448016f3d6b",
            "86453d5d934e42f58e59c2f1a25cdb8c",
            "37631c04429d489d87debd433505bae1"
          ]
        },
        "id": "30fb2806",
        "outputId": "589fab5a-3704-4155-9b34-80c692d016d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f94484674e4319af71c9c90725f509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebfff18534ba4a14ae396820af4ff824"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset('/content/data/filtered')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d72798b9",
      "metadata": {
        "id": "d72798b9"
      },
      "source": [
        "Execute the function to transform the filtered dataset to the format explained above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a18e6e",
      "metadata": {
        "id": "c1a18e6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "d7de2cd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a1b1f09d656c4f2684a00261bd18efd9",
            "ecbdd7505bc14f36a0492f1e33c6b986",
            "89dda46f287247c9923fae73bad6a7e9",
            "cbe4a6e006f146f89b3b2e6ab1593ef4",
            "454250d70b804d1e814d636e82e65a27",
            "03b1a6331223426d9ce3867462b2f2b6",
            "7311901952ab4912b518aff660bfb84a",
            "a91cf3936f8c41beaf6f40d9720b5232",
            "bc8af20c2d914c2f93e63971b2a59975",
            "ec843417a6c24958b606323725f5d198",
            "da478aa87ff2472c898ef4ba2f4c9c04",
            "b99f7c5d62554e449070c9d906f2db89",
            "91c769571cc44985b50f53ea0af136c0",
            "7aadcb3ffc004df485099c83014afeed",
            "aab5785996684f669015d31b744c3cd3",
            "5e9cb95201354753aac8cbec4a38eb70",
            "86b08a8c23fe4a06ab5ec4e126034909",
            "54322985e0414444943b5700c0ed758f",
            "9d95b9de0d9844799dbe8799790c5320",
            "1a5f711f35ea4719828d9b7e5835a67c",
            "a86543cd6b444f95a98b265c26cd27ed",
            "196dc4cc30f848259cf5eceb82cab227"
          ]
        },
        "id": "d7de2cd3",
        "outputId": "1db89b07-f6ce-48fe-f600-fec12dc66a49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1778 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1b1f09d656c4f2684a00261bd18efd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b99f7c5d62554e449070c9d906f2db89"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "### credit: https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k ###\n",
        "\n",
        "# Define a function to transform the data\n",
        "def transform_to_template(example):\n",
        "    conversation_text = example['text']\n",
        "    segments = conversation_text.split('###')\n",
        "\n",
        "    reformatted_segments = []\n",
        "\n",
        "    # Iterate over pairs of segments\n",
        "    for i in range(1, len(segments) - 1, 2):\n",
        "        human_text = segments[i].strip().replace('Human:', '').strip()\n",
        "\n",
        "        # Check if there is a corresponding assistant segment before processing\n",
        "        if i + 1 < len(segments):\n",
        "            assistant_text = segments[i+1].strip().replace('Assistant:', '').strip()\n",
        "\n",
        "            # Apply the new template\n",
        "            reformatted_segments.append(f'<s>[INST] {human_text} [/INST] {assistant_text} </s>')\n",
        "        else:\n",
        "            # Handle the case where there is no corresponding assistant segment\n",
        "            reformatted_segments.append(f'<s>[INST] {human_text} [/INST] </s>')\n",
        "\n",
        "    return {'text': ''.join(reformatted_segments)}\n",
        "\n",
        "\n",
        "# Apply the transformation\n",
        "template_dataset = dataset.map(transform_to_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7ea06a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ea06a56",
        "outputId": "3d19811a-8259-499a-accd-59a9f2039e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1778\n",
            "189\n"
          ]
        }
      ],
      "source": [
        "print( len(template_dataset['train']))\n",
        "print( len(template_dataset['test']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f987d4f",
      "metadata": {
        "id": "8f987d4f"
      },
      "source": [
        "Let's display a sample to inspect if our training set is in the right format as shown in the screenshot above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1f4713f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f4713f0",
        "outputId": "884ca012-3205-4d74-b38e-eed6af3fee96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': [\"<s>[INST] I want to start doing astrophotography as a hobby, any suggestions what could i do? [/INST] Getting started in astrophotography can seem daunting, but with some patience and practice, you can become a master of the craft. To begin, you'll need a good camera and lens, a tripod, and a dark sky location free of light pollution. You will also need to learn about the basics of astrophotography, such as what camera settings to use, how to capture star trails, and the best techniques for tracking celestial objects. You can also purchase or rent different types of telescopes, depending on what types of objects you want to capture. Additionally, it's important to keep up with the latest astrophotography news and trends. Once you have the necessary equipment and knowledge, you can start shooting and experimenting with different techniques to get the best results. </s><s>[INST] Can you tell me more?  What would you recommend as a basic set of equipment to get started with?  How much will it cost? [/INST] Astrophotography can be a fun and rewarding hobby, and here are some more in depth suggestions for you to get started:\\n\\n    Equipment: As a beginner, you will need a camera that is capable of taking long exposures and manual control over the settings. A good starting point would be a digital SLR (DSLR) camera or a mirrorless camera. You will also need a sturdy tripod, a fast wide-angle lens (f/2.8 or faster), and a remote shutter release cable to minimize camera shake during long exposures.\\n\\n    Location: Look for a location with minimal light pollution and a clear view of the night sky. Check online maps to find the best spots near you.\\n\\n    Settings: Start with a wide-angle lens and set your camera to manual mode. Set your aperture to f/2.8 or wider, ISO to 800 or 1600, and experiment with different exposure times (30 seconds to 2 minutes).\\n\\n    Focus: Focus the lens on the stars using live view and manual focus. You may also need to use a Bahtinov mask to achieve accurate focus.\\n\\n    Editing: After you've taken your photos, use editing software such as Adobe Lightroom or Photoshop to adjust the exposure, contrast, and color balance to get the best results.\\n\\nThe cost of equipment will depend on the type of camera and lens you choose, but a basic setup can cost anywhere from $500 to $3000. However, you don't need to start with the most expensive equipment to get good results. As you improve, you can upgrade your equipment and add additional accessories such as filters and tracking mounts.\\n\\nRemember, astrophotography is a hobby that requires patience and practice, so don't be discouraged if your first few attempts don't turn out as well as you had hoped. Keep experimenting and learning, and you'll soon be able to capture stunning images of the night sky! </s>\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "template_dataset['train'][2:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497ba7bb",
      "metadata": {
        "id": "497ba7bb"
      },
      "source": [
        "Save the preprocessed dataset to the directory `../data/ds_preprocess`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0deb3e24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9886f6c146a540d7acf147ed2f23cc59",
            "e4863eddbad944b08753e0db7458efb8",
            "1cbdd44882164abcbf079aeeb3793b41",
            "6d46ef43c99e4f6186387a31623be70a",
            "bfbc03b2dc7446ceb47e233fdc382a0d",
            "810321cd62ca40ab84770d1ec7d717d5",
            "4155e6c0d8bf4ca28532c64359aa3e67",
            "5dc5006793234df393ee92cdb56be8e6",
            "583c99edb9864a9d9c4714d53d62d9b1",
            "4c95708f5e5b4fb1a969dfcfa4b43461",
            "a13a5b995631466c9987481967ca47dc",
            "ee777dd578f64255885af27fb93dfaf9",
            "330ab84138b34d229ac1af2c6156c5fa",
            "97368aaf11ac4cb9841a74587217f330",
            "024162c5b4c8417c817a3c73a3ffc37c",
            "6d5bccd0a0c5465a9ce40fc3be30250a",
            "b551a09593f54128b05caa052a47e2a3",
            "01abc413f8df4e779031e68d5c48da31",
            "52165b2414c049d99d33c76b0dccdad1",
            "2f70c1dd71614dd599dda8ed0c30f693",
            "b7944c84244941deac06a318df60a7ac",
            "42e63149a2dd40bc93d020a328a1ad79"
          ]
        },
        "id": "0deb3e24",
        "outputId": "54245784-f72e-4157-9470-4bd35cc748ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/1778 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9886f6c146a540d7acf147ed2f23cc59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/189 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee777dd578f64255885af27fb93dfaf9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "os.makedirs(\"/content/data/ds_preprocess\", exist_ok=True)\n",
        "template_dataset.save_to_disk('/content/data/ds_preprocess')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3be1642c",
      "metadata": {
        "id": "3be1642c"
      },
      "source": [
        "## Fine-tuning LLAMA 2\n",
        "\n",
        "As mentioned earlier in the notebook, our choice model for finetuning is the `Llama-2-7b-chat`. Below is the list of walkthrough steps to complete the task.\n",
        "\n",
        "- Convert the `Llama-2-7b-chat` to Hugging Face transformer format\n",
        "- Set the paths to the model and load the dataset\n",
        "- Load the model tokenizer\n",
        "- Set the training parameter\n",
        "- Configure the Parameter Efficient Fine Tuning with LoRA\n",
        "- Apply 4-bits quantization\n",
        "- Setup the trainer to start the finetuning process\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c6dbb1c",
      "metadata": {
        "id": "0c6dbb1c"
      },
      "source": [
        "### Convert model to Hugging Face Transformers Format\n",
        "We will convert our model checkpoint to the Hugging Face transformer format. The benefits are as follows:  \n",
        "\n",
        "- Delivers a convenient way to finetune the Llama2 model with limited GPU computing resources (like laptops, workstations, or Google Colab) through the use of some technique that a transformer-compatible\n",
        "- Ability to immediately use a model on a given input text using transformer Pipelines.\n",
        "- The use of transformers `Pipelines` group together the pre-trained model with the preprocessing that was used during that training to enable quick inferencing.\n",
        "\n",
        "\n",
        "To convert our model checkpoint, we use the `convert_llama_weights_to_hf.py` script located on [GitHub](https://github.com/cedrickchee/transformers-llama/tree/llama_push/src/transformers/models/llama).\n",
        "\n",
        "- `--input_dir`: denotes the directory to the llama model to be converted\n",
        "- `--model_size`: represents the llama model parameter size\n",
        "- `--out_dir`: the directory to save the converted model\n",
        "\n",
        "<img src=\"images/llama-hf.png\" height=\"550px\" width=\"900px\" />\n",
        "\n",
        "If you already have the Hugging Face format of the model `Llama-2-7b-chat-hf`, you can skip running the cell below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf0c5ab",
      "metadata": {
        "id": "8bf0c5ab",
        "outputId": "adc668ea-13f6-45f3-9c3a-70ed700f35cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Fetching all parameters from the checkpoint at ../../model/Llama-2-7b-chat.\n",
            "Loading the checkpoint in a Llama model.\n",
            "Loading checkpoint shards: 100%|████████████████| 33/33 [00:06<00:00,  4.85it/s]\n",
            "Saving in the Transformers format.\n"
          ]
        }
      ],
      "source": [
        "%time !python3 ../../source_code/Llama2/llama/convert_llama_weights_to_hf.py \\\n",
        "--input_dir ../../model/Llama-2-7b-chat --model_size 7B --output_dir ../../model/Llama-2-7b-chat-hf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "369d52b7",
      "metadata": {
        "id": "369d52b7"
      },
      "source": [
        "**Exepected Output:**\n",
        "```python\n",
        "...\n",
        "https://github.com/huggingface/transformers/pull/24565\n",
        "Fetching all parameters from the checkpoint at ../model/Llama-2-7b-chat.\n",
        "Loading the checkpoint in a Llama model.\n",
        "Loading checkpoint shards: 100%|████████████████| 33/33 [00:06<00:00,  4.95it/s]\n",
        "Saving in the Transformers format.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **주의**\n",
        "메모리 이슈로 인해 런타임을 재시작을 하는 경우  **`세션 다시시작`**을 누르시면 됩니다.\n",
        "절대로 런타임 연결해제를 누르면 안됩니다. 설치된 라이브러리와 다운로드한 체크포인트, 데이터가 모두 사라집니다.\n"
      ],
      "metadata": {
        "id": "hddfaB3SP1Og"
      },
      "id": "hddfaB3SP1Og"
    },
    {
      "cell_type": "code",
      "source": [
        "# In some cases where you have access to limited computing resources, you might have to uncomment os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\" if you run into not enough memory issue\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import json\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from langdetect import detect\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "import re\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\""
      ],
      "metadata": {
        "id": "eBV3TfQMLb9Q"
      },
      "id": "eBV3TfQMLb9Q",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cb2744db",
      "metadata": {
        "id": "cb2744db"
      },
      "source": [
        "Now, we can initialize the path to our transformer format model and load the transformed/preprocessed training dataset from the directory where it was saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "902a087c",
      "metadata": {
        "id": "902a087c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# initailize path to the base model\n",
        "base_model = \"/content/model/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# set the path to the dataset template\n",
        "data_path = \"/content/data/ds_preprocess/train\"\n",
        "\n",
        "# set the path to the dataset template\n",
        "eval_path = \"/content/data/ds_preprocess/test\"\n",
        "\n",
        "# load the transformed dataset\n",
        "train_ds = load_from_disk(data_path)\n",
        "eval_ds = load_from_disk(eval_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a32a21cb",
      "metadata": {
        "id": "a32a21cb"
      },
      "source": [
        "### Loading tokenizer\n",
        "\n",
        "Tokenization is breaking a text into sentences, words, or sub-words. Each word or sentence in a text is considered as a token. Tokenization allows a detailed text data analysis when broken into smaller units. The [LLaMA tokenizer](https://huggingface.co/docs/transformers/en/model_doc/llama2) is a byte-pair-encoding (BPE) model based on [sentencepiece](https://aclanthology.org/P16-1162/), an unsupervised text tokenizer and detokenizer for Neural Network-based text generation systems that predetermined the vocabulary size prior to the neural model training.\n",
        "\n",
        "In the cell below, we load the tokenizer from our base model directory and set the parameters:\n",
        "\n",
        "- **pad_token**: a special token used to make arrays of tokens the same size for batching purposes.\n",
        "- **padding_side**: side to pad\n",
        "\n",
        "A comprehensive list of Llama tokenizer parameters can be found [here](https://huggingface.co/docs/transformers/en/model_doc/llama2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cdf1a4f8",
      "metadata": {
        "id": "cdf1a4f8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2338835",
      "metadata": {
        "id": "c2338835"
      },
      "source": [
        "### Set Training Hyperparameters\n",
        "\n",
        "Training hyperparameters are customized using the `TrainingArguments` class. The class provides an API that offers a wide range of options to customize and optimize the training process. Please find a comprehensive description of the hyperparameters [here](https://huggingface.co/transformers/v3.0.2/main_classes/trainer.html#transformers.TrainingArguments). You can further modify the values of the hyperparameters in the next cell after the complete finetune process and rerun the cells to see how it impact on the training outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93e7375b",
      "metadata": {
        "tags": [],
        "id": "93e7375b"
      },
      "source": [
        "### Configure PEFT With LoRA\n",
        "\n",
        "Finetuning large language pre-trained models is computationally costly. Our main goal is to accelerate our finetuning process with minimal memory consumption. A method to achieve that is to use a state-of-the-art [Parameter-Efficient Finetuning (PEFT)](https://github.com/huggingface/peft/tree/main) approach. [PEFT](https://arxiv.org/abs/2305.16742) allows finetuning a small number of (extra) model parameters instead of all the model's parameters, and this significantly decreases the computational and storage costs. One of the ways to implement PEFT is to adopt the Low-Rank Adaptation (LoRA) technique. Lora makes finetuning more efficient by greatly reducing the number of trainable parameters for downstream tasks. It does this by freezing the pre-trained model weights and injecting trainable rank decomposition matrices into each layer of the Transformer architecture. According to the [authors of LoRA](https://arxiv.org/abs/2106.09685), Aside from reducing the number of trainable parameters by 10k times, it also reduces the GPU consumption by 3x, thus delivering high throughput with no inference latency. For quick background on LoRA, please follow this [link](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora).\n",
        "\n",
        "<center><img src=\"images/lora-arch.png\" height=\"500px\" width=\"900px\"  /></center>\n",
        "<center>  LoRA reparametrization and Weight merging. <a href=\"https://huggingface.co/docs/peft/main/en/conceptual_guides/lora\"> View source</a> </center>\n",
        "\n",
        "LoRA techniques are applied through `LoraConfig`, which provides PEFT parameters that control how the method is applied to the base model. A description of the parameter used in the cell below is given as follows:\n",
        "\n",
        "- **lora_alpha**: LoRA scaling factor\n",
        "- **lora_dropout**: The dropout probability for LoRA layers.\n",
        "- **r**: the rank of the update matrices, expressed in int. Lower rank results in smaller update matrices with fewer trainable parameters.\n",
        "- **bias**: Specifies if the bias parameters should be trained. It can be 'none', 'all', or 'lora_only'.\n",
        "- **task_type**: Possible task types which include `CAUSAL_LM`, `FEATURE_EXTRACTION`, `QUESTION_ANS`, `SEQ_2_SEQ_LM`, and `SEQ_CLS and TOKEN_CLS`.   \n",
        "\n",
        "Because the task we want to perform is text generation, we have set the task_type to Causal language model `(CAUSAL_LM)`, which is frequently used for text generation tasks. Please run the cell below to set up the LoRA configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d5416b2c",
      "metadata": {
        "id": "d5416b2c"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbead7ee",
      "metadata": {
        "id": "dbead7ee"
      },
      "source": [
        "### 4-bit quantization configuration\n",
        "\n",
        "Model quantization is a popular deep-learning optimization method in which model data—network parameters and activations—are converted from floating-point to lower-precision representation, typically using 8-bit integers. Quantization represents data with fewer bits, making it a useful technique for reducing memory usage and accelerating inference, especially in large language models (LLMs). It can be combined with PEFT methods to make it easier to train and load LLMs for inference.\n",
        "\n",
        "<center><img src=\"images/quantization.png\" height=\"400px\" width=\"700px\" /></center>\n",
        "<center> <a href=\"https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt/\" > source: Using Quantization Aware Training with NVIDIA TensorRT</a></center>\n",
        "\n",
        "Several ways and algorithms to quantize a model including can be found [here](https://huggingface.co/docs/peft/main/en/developer_guides/quantization). A library to easily implement quantization and integrate with transformers is the `bitsandbytes` library. The library provides config parameters to quantize a model to 8 or 4 bits using the `BitsAndBytesConfig` class. The 4 bits parameters used in the cell below are described as follows:\n",
        "\n",
        "- **load_in_4bit**: set `True` to quantize the model to 4-bits when you load it\n",
        "- **bnb_4bit_quant_type**: set to `\"nf4\"` to use a special 4-bit data type for weights initialized from a normal distribution\n",
        "- **bnb_4bit_use_double_quant**: set `True` to use a nested quantization scheme to quantize the already quantized weights\n",
        "- **bnb_4bit_compute_dtype**: set to `torch.float16` or `torch.bfloat16` to use bfloat16 for faster computation\n",
        "\n",
        "Run the cell below to set the 4-bit quantization for our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "90cd071b",
      "metadata": {
        "id": "90cd071b"
      },
      "outputs": [],
      "source": [
        "\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edb0af67",
      "metadata": {
        "id": "edb0af67"
      },
      "source": [
        "### Loading Base Model\n",
        "\n",
        "The next step is to load our base model `(Llama-2-7b-chat-hf)` with the causal language model class used for the text generation task. We do this by passing the base model, quantization config, and GPU device ID to the `AutoModelForCausalLM` object, as shown in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f578e33f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a515158a79a44830ace5b3e78d862afc",
            "4047c35519b042b381fa39b538c15f5e",
            "3e51927170e84e7a84d4562af40e9941",
            "874beaf30f4547ac858769cafc7338f7",
            "324cdb1a21d344438408087f44727cac",
            "1fa4bebb0bcb4d5382671d59930a2452",
            "780f00e43fd64ab39fcbe3e22008af41",
            "16f3138c916d46cd8212e7c96fd386aa",
            "1cecfbfc9e354da4bfab8e1b636e593b",
            "4785afd7c4824ddf8e4700e2a6f17262",
            "0e54bfe25d754dd3a29647ef5b80ed06"
          ]
        },
        "id": "f578e33f",
        "outputId": "d5ff1fb6-4e0e-4d9c-ae28-b5a8c4d4390e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a515158a79a44830ace5b3e78d862afc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-mMV3mbFCbm",
        "outputId": "2e18824e-03c9-4a0c-f619-869070429ac9"
      },
      "id": "B-mMV3mbFCbm",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jul  2 08:08:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0             27W /   70W |    6676MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f996091",
      "metadata": {
        "id": "6f996091"
      },
      "source": [
        "### Set the Trainer Hyperparameters\n",
        "\n",
        "To initiate our model trainer, we create a trainer object from [Supervised fine-tuning (SFT)](https://huggingface.co/docs/trl/en/sft_trainer). SFT is part of the integrated transformer [Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/en/index) tools used to train transformer language models using Reinforcement Learning. Others include [Reward Modeling step (RM)](https://huggingface.co/docs/trl/en/reward_trainer) and  Proximal [Policy Optimization (PPO)](https://arxiv.org/abs/1707.06347). In our SFT trainer object, we set our model, training dataset, PEFT config  object, model tokenizer, and training argument parameter. We also specify the field (`text`) to use within our dataset.\n",
        "\n",
        "**Note:** *If running on a single DGX A100 GPU, modify the value of `max_seq_length` to 1024 or set it to none (as default).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1770d58f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1770d58f",
        "outputId": "c2a2764f-4bb9-4f4e-e310-e5637f92d286"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "average_tokens_across_devices is set to True but it is invalid when world size is1. Turn it to False automatically.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "\n",
        "\n",
        "sft_cfg = SFTConfig(\n",
        "    # — data & formatting\n",
        "    dataset_text_field=\"text\",   # which column to read\n",
        "    max_seq_length=128,          # truncate / pad length\n",
        "\n",
        "    # — training schedule\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=1,\n",
        "\n",
        "    # — optimization\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    warmup_ratio=0.03,\n",
        "    max_grad_norm=0.3,\n",
        "\n",
        "    # — precision & logging\n",
        "    bf16=True,\n",
        "    fp16=False,\n",
        "    save_steps=25,\n",
        "    logging_steps=1,\n",
        "\n",
        "    # — output & reporting\n",
        "    output_dir=\"/content/model/results\",\n",
        "    save_total_limit=3,\n",
        "    run_name=None,               # no default W&B run name\n",
        "    report_to=[\"tensorboard\"],   # ONLY TensorBoard, no \"wandb\"\n",
        "\n",
        "    # — packing\n",
        "    packing=False,               # example‐packing off\n",
        "    eval_packing=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = SFTTrainer(\n",
        "    model,                   #  4-bit + LoRA model\n",
        "    train_dataset=train_ds,  #  HF train dataset\n",
        "    args=sft_cfg,            # 3 SFTConfig object\n",
        "    eval_dataset=eval_ds,    #   eval dataset\n",
        "    peft_config=lora_config,   #   LoRA settings\n",
        "    processing_class=tokenizer,  # pass tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w91FlpjoFrHA",
        "outputId": "14d8c9e5-e1f9-451c-a119-98684b2c58f7"
      },
      "id": "w91FlpjoFrHA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='98' max='223' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 98/223 22:00 < 28:38, 0.07 it/s, Epoch 0.43/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.693700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.601900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.589400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.441700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.327700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.022700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.024500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.888800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.916700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.828200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.071700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>2.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.847700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.784100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.919100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.544500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.486000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.718400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.511800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.605900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.791700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.391400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.887500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.246200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.635800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.377600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.570400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.798700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.610100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.888800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.878800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.556100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.574700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.872300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.348800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.313200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.580600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.643500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.656300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.438800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.414400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.331900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.427700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.541800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.444800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.513000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.789000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.106400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.769000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.291700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.276400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.301700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.601600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.583600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.163800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.702700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.517100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.551900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.254500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.363300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.359700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.503100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.509300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.349400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.276900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.535600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.673500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.322900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.367700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.268800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.581600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.254100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.608100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.223700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.721400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.739600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.281800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.318000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.374300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.450900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.718900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.496700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fb03171",
      "metadata": {
        "id": "2fb03171"
      },
      "source": [
        "Run the cell below to train the SFT trainer object"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47f83ad",
      "metadata": {
        "id": "f47f83ad"
      },
      "source": [
        "Save the finetuning model and tokenizer in the directory  `/content/model/Llama-2-7b-chat-hf-finetune`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "615a1716",
      "metadata": {
        "id": "615a1716"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "new_model = \"/content/model/Llama-2-7b-chat-hf-finetune\"\n",
        "trainer.model.save_pretrained(new_model)\n",
        "trainer.tokenizer.save_pretrained(new_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a89a99e6",
      "metadata": {
        "id": "a89a99e6"
      },
      "source": [
        "## Inferencing\n",
        "\n",
        "Now that we completed our finetuning process, we can run a quick inference to test how our new model is performing. To do that, we will create the following:\n",
        "\n",
        "- a transformer pipeline with four parameter inputs: `model`, `tokenizer`, `max_length`, and `task`.  \n",
        "- format prompt as: `f\"<s>[INST] {prompt} [/INST]\"`\n",
        "- pass the prompt into the pipeline object and get result.\n",
        "\n",
        "```python\n",
        "\n",
        "inf_pipeline = pipeline(model=model, tokenizer=tokenizer, max_length=200, task=\"text-generation\")\n",
        "prompt = inf_pipeline(f\"<s>[INST] {prompt} [/INST]\")\n",
        "result = inf_pipeline(prompt)\n",
        "print(result[0]['generated_text'])\n",
        "```\n",
        "You can modify the `max_length` to decide the length of text generated by the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "572eaa38",
      "metadata": {
        "id": "572eaa38"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_inference(prompt):\n",
        "    inf_pipeline = pipeline(model=model, tokenizer=tokenizer, max_length=128, task=\"text-generation\")\n",
        "    prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
        "    result = inf_pipeline(prompt)\n",
        "    print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c26ac9",
      "metadata": {
        "id": "46c26ac9"
      },
      "outputs": [],
      "source": [
        "prompt = \"explain what is astrophotography?\"\n",
        "run_inference(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b041519",
      "metadata": {
        "id": "4b041519"
      },
      "source": [
        "**Likely output:**\n",
        "\n",
        "```bash\n",
        "<s>[INST] explain what is astrophotography? [/INST] Astrophotography is the branch of photography that deals with the photographing of celestial objects such as stars, planets, galaxies, and other astronomical phenomena. Astrophotographers use specialized cameras and telescopes to capture images of these objects, often in low light conditions. Astrophotography requires a great deal of patience, skill, and knowledge, as photographers must be able to accurately track the movement of celestial objects and compensate for the effects of light pollution and atmospheric distortion. Astrophotography has become increasingly popular in recent years, with many amateur astronomers and professional photographers engaging in this hobby and art form.\n",
        "\n",
        "Astrophotography can be done using a variety of techniques, including long exposure times, tracking mounts, and using narrow-band filters to\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ee30c3",
      "metadata": {
        "id": "d4ee30c3"
      },
      "outputs": [],
      "source": [
        "prompt = \"can you explain further?\"\n",
        "run_inference(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9e6f88e",
      "metadata": {
        "id": "a9e6f88e"
      },
      "source": [
        "**Likely output:**\n",
        "\n",
        "```bash\n",
        "<s>[INST] can you explain further? [/INST] Sure, I'd be happy to explain further! Could you please provide more context or clarify what you're asking about? 😃 👍 💡 🖊 📝 📅 🕰 🕰️ 🕳️ 🕷️ 🕸️ 🕷️ 🕸️ 🕳️ 🕷️ 🕸️ 🕳️ 🕷️ 🕸️ 🕰️ 🕰️ 🕳️ 🕷️ 🕸️ 🕳️ 🕷️ 🕸️ 🕰️\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebee19b",
      "metadata": {
        "tags": [],
        "id": "0ebee19b"
      },
      "outputs": [],
      "source": [
        "prompt = \"I want you to explain further on astrophotography\"\n",
        "run_inference(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80897b7e",
      "metadata": {
        "id": "80897b7e"
      },
      "source": [
        "**Likely output:**\n",
        "\n",
        "```bash\n",
        "\n",
        "<s>[INST] I want you to explain futher on astrophotography [/INST] Sure, I d be happy to explain further on astrophotography. Astrophotography is the process of capturing images of celestial objects such as stars, planets, galaxies, and other astronomical phenomena. It involves using specialized cameras and techniques to capture high-quality images of these objects in the night sky.\n",
        "\n",
        "There are several key components to astrophotography:\n",
        "\n",
        "    Camera: Astrophotography cameras are designed specifically for capturing images of celestial objects. They typically have large sensors, fast lenses, and specialized features such as built-in equatorial mounts, motorized tracking systems, and cooling systems to reduce noise and improve image quality.\n",
        "\n",
        "    Telescope: A telescope is used to gather light from the celestial object being photographed. There are several types of\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3681804e",
      "metadata": {
        "id": "3681804e"
      },
      "source": [
        "### Reload model in FP16 and merge with LoRA weights\n",
        "\n",
        "To have our model as a single entity for ease of use and widened task coverage, we reload it in fp16 mode and merge it with the LoRA weights using `model.merge_and_unload()`. The tokenizer is reloaded, pad, and saved along with the merged model in the same directory, `/content/model/Llama-2-7b-chat-hf-merged`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de23ad6",
      "metadata": {
        "id": "9de23ad6"
      },
      "outputs": [],
      "source": [
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "load_base_model = AutoModelForCausalLM.from_pretrained( base_model, torch_dtype=torch.float16, low_cpu_mem_usage=True, return_dict=True, device_map={\"\": 0})\n",
        "\n",
        "model = PeftModel.from_pretrained(load_base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca5d78a",
      "metadata": {
        "id": "6ca5d78a"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"/content/model/Llama-2-7b-chat-hf-merged\", safe_serialization=True)\n",
        "tokenizer.save_pretrained(\"/content/model/Llama-2-7b-chat-hf-merged\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bec3418",
      "metadata": {
        "id": "2bec3418"
      },
      "source": [
        "**expected output**:\n",
        "```python\n",
        "('/content/model/Llama-2-7b-chat-hf-merged/tokenizer_config.json',\n",
        " '/content/model/Llama-2-7b-chat-hf-merged/special_tokens_map.json',\n",
        " '/content/model/Llama-2-7b-chat-hf-merged/tokenizer.model',\n",
        " '/content/model/Llama-2-7b-chat-hf-merged/added_tokens.json',\n",
        " '/content/model/Llama-2-7b-chat-hf-merged/tokenizer.json')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f10838",
      "metadata": {
        "id": "d0f10838"
      },
      "source": [
        "# additional work for meerkat model\n",
        "\n",
        "meerkat is medical domain sllm model from mistal-8b from Korea University.\n",
        "\n",
        "[Meerkat-7B-v1.0](https://huggingface.co/dmis-lab/meerkat-7b-v1.0)is an instruction-tuned medical AI system that surpasses the passing threshold of 60% for the United States Medical Licensing Examination (USMLE) for the first time among all 7B-parameter models. The model was trained using [new synthetic dataset](https://huggingface.co/datasets/dmis-lab/meerkat-instructions) consisting of high-quality chain-of-thought reasoning paths sourced from 18 medical textbooks, along with diverse instruction-following datasets. This equips the model with high-level medical reasoning capabilities required for solving complex medical problems. [Nature Paper](https://www.nature.com/articles/s41746-025-01653-8)  [meerkat model](https://huggingface.co/dmis-lab/meerkat-7b-v1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf8a62fd",
      "metadata": {
        "id": "bf8a62fd"
      },
      "source": [
        "# Instruction-Tuning Llama-2-7b-chat on Meerkat dataset\n",
        "\n",
        "In this notebook we will:\n",
        "\n",
        "1. Reset the kernel and Import required libraries (and optionally fix CUDA OOM issues).  \n",
        "2. Load & merge the nine Meerkat JSONL files into one `Dataset`.  \n",
        "3. Transform each example into the `<s>[INST]…[/INST]…</s>` template.  \n",
        "4. Split into train/eval.  \n",
        "5. Initialize tokenizer, 4-bit quantized model, and LoRA PEFT config.  \n",
        "6. Set up `SFTTrainer` and `TrainingArguments`.  \n",
        "7. Train and save as **Llama-2-7b-chat-meerkat**.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3c31d2",
      "metadata": {
        "id": "9b3c31d2"
      },
      "source": [
        "Reset the kernel and check the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e399c83b",
      "metadata": {
        "id": "e399c83b",
        "outputId": "163977bc-8797-45ca-8704-4cd3ac3335ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May  8 01:29:38 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |\n",
            "| N/A   31C    P0              76W / 400W |      7MiB / 81920MiB |     10%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89752e1",
      "metadata": {
        "id": "e89752e1"
      },
      "outputs": [],
      "source": [
        "# 1) Imports + optional CUDA memory workaround\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# If you hit CUDA OOM, uncomment this line:\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")                    # ignore Python warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "becf87a4",
      "metadata": {
        "id": "becf87a4"
      },
      "source": [
        "## 2a) download meerkat dataset\n",
        "from hugginface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b9475a",
      "metadata": {
        "id": "88b9475a",
        "outputId": "52d3aaef-7f85-4f7b-f06e-4699ade14346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[skip] chatdoctor-cleaned.jsonl already exists\n",
            "[skip] liveqa.jsonl already exists\n",
            "[skip] medbooks-18-cot.jsonl already exists\n",
            "[skip] medicationqa.jsonl already exists\n",
            "[skip] medinstruct-52k.jsonl already exists\n",
            "[skip] medmcqa.jsonl already exists\n",
            "[skip] medqa-cot.jsonl already exists\n",
            "[skip] medqa-dialog.jsonl already exists\n",
            "[skip] mts-dialog.jsonl already exists\n",
            "✅ All files downloaded to /workspace/data_meerkat\n",
            "CPU times: user 7.72 ms, sys: 7.21 ms, total: 14.9 ms\n",
            "Wall time: 632 ms\n"
          ]
        }
      ],
      "source": [
        "%time !python3 /content/source_code/Llama2/download-meerkat-ds.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4913f833",
      "metadata": {
        "id": "4913f833"
      },
      "source": [
        "## 2b) Load & merge the Meerkat JSONL files\n",
        "\n",
        "We point at `../../data_meerkat`, find all `.jsonl` files, and load them into a single `DatasetDict` under the `\"train\"` split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0375d03",
      "metadata": {
        "id": "e0375d03",
        "outputId": "59c714dc-bf09-4f79-e818-46d15c8c0edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 441,034 total examples.\n"
          ]
        }
      ],
      "source": [
        "# adjust this path if needed\n",
        "meerkat_dir = \"/content/data_meerkat\"\n",
        "\n",
        "# collect all JSONL paths\n",
        "files = [\n",
        "    os.path.join(meerkat_dir, fname)\n",
        "    for fname in os.listdir(meerkat_dir)\n",
        "    if fname.endswith(\".jsonl\")\n",
        "]\n",
        "\n",
        "# load into one big 'train' split\n",
        "raw = load_dataset(\"json\", data_files={\"train\": files})\n",
        "raw_ds = raw[\"train\"]\n",
        "\n",
        "print(f\"Loaded {len(raw_ds):,} total examples.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d45268d4",
      "metadata": {
        "id": "d45268d4"
      },
      "source": [
        "## 3) Transform examples into the `<s>[INST]…[/INST]…</s>` format\n",
        "\n",
        "We handle the various Meerkat schemas (`instruction`/`output`, `question`/`answer` + optional CoT `explanation` + `options`) and collapse each into a single string field `\"text\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5b9002",
      "metadata": {
        "id": "cc5b9002",
        "outputId": "e49d6666-afed-45f8-af25-04b0d73c335b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed to template, example:\n",
            "<s>[INST]  [/INST]  </s>\n"
          ]
        }
      ],
      "source": [
        "def transform_meerkat(example):\n",
        "    # 3a) if instruction/output format\n",
        "    if \"instruction\" in example and \"output\" in example:\n",
        "        prompt = example[\"instruction\"].strip()\n",
        "        response = example[\"output\"].strip()\n",
        "    # 3b) if QA + CoT format\n",
        "    elif \"question\" in example and \"answer\" in example:\n",
        "        explan = example.get(\"explanation\", \"\").strip()\n",
        "        # final answer sentence\n",
        "        final = f\"{explan} Therefore, the answer is {example['answer']}.\"\n",
        "        # prepend any multiple‐choice options\n",
        "        opts = example.get(\"options\")\n",
        "        if isinstance(opts, dict):\n",
        "            optstr = \" \".join(f\"({k}) {v}\" for k, v in opts.items())\n",
        "            prompt = example[\"question\"].strip() + \" Options: \" + optstr\n",
        "        else:\n",
        "            prompt = example[\"question\"].strip()\n",
        "        response = final\n",
        "    else:\n",
        "        # fallback to text + answer\n",
        "        prompt = example.get(\"text\", \"\").strip()\n",
        "        response = example.get(\"answer\", \"\").strip()\n",
        "\n",
        "    return {\"text\": f\"<s>[INST] {prompt} [/INST] {response} </s>\"}\n",
        "\n",
        "# apply and drop old columns\n",
        "ds = raw_ds.map(transform_meerkat, remove_columns=raw_ds.column_names)\n",
        "print(\"Transformed to template, example:\")\n",
        "print(ds[0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ab99b0",
      "metadata": {
        "id": "b5ab99b0"
      },
      "source": [
        "## 4) Train/Validation Split\n",
        "\n",
        "We hold out 5% of the data for evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf818f5",
      "metadata": {
        "id": "2cf818f5",
        "outputId": "bc9af579-4f9d-452c-e213-0a9904b3f8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ train size: 418,982\n",
            "→ eval  size: 22,052\n"
          ]
        }
      ],
      "source": [
        "split = ds.train_test_split(test_size=0.05, seed=42)\n",
        "train_dataset = split[\"train\"]\n",
        "eval_dataset  = split[\"test\"]\n",
        "\n",
        "print(f\"→ train size: {len(train_dataset):,}\")\n",
        "print(f\"→ eval  size: {len(eval_dataset):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742eb4ed",
      "metadata": {
        "id": "742eb4ed"
      },
      "source": [
        "## 5) Initialize Tokenizer & Model + LoRA+4-bit Quant\n",
        "\n",
        "- **Tokenizer** from `Llama-2-7b-chat-hf`  \n",
        "- **4-bit quant** (NF4) for the model to reduce VRAM.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536ceeef",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fc4c0bb5ca8742889a73678f9ee55b0b"
          ]
        },
        "id": "536ceeef",
        "outputId": "ac5952a8-59d7-4fe4-cf58-318da629d14b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc4c0bb5ca8742889a73678f9ee55b0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "base_model = \"../../model/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# 4-bit quant config\n",
        "quant_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")\n",
        "\n",
        "# load quantized model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    quantization_config=quant_cfg,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b62edbb",
      "metadata": {
        "id": "4b62edbb",
        "outputId": "c6ad13d9-33bd-4e90-9d90-25bcf5e487a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May  8 01:30:19 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |\n",
            "| N/A   31C    P0              69W / 400W |   4629MiB / 81920MiB |      3%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A   3002220      C   /usr/bin/python                            4616MiB |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71033324",
      "metadata": {
        "id": "71033324"
      },
      "source": [
        "## 6) Set up TrainingArguments & SFTTrainer\n",
        "\n",
        "- **LoRA PEFT** config r=64, α=16, dropout=0.1.\n",
        "We mirror your previous hyperparameters:  \n",
        "- 2 epochs, batch_size=1, LR=2e-4, save/log every 25 steps, no fp16/bf16, constant LR schedule, TensorBoard logging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1cd76cd",
      "metadata": {
        "id": "c1cd76cd"
      },
      "outputs": [],
      "source": [
        "# LoRA config\n",
        "peft_cfg = LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abeaa1c2",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "65c4e67d2e324a889dec8e30e99dc8cd"
          ]
        },
        "id": "abeaa1c2",
        "outputId": "95ea4e4b-647a-4abc-a903-f91b8342c47d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65c4e67d2e324a889dec8e30e99dc8cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/22052 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"../../model/results-meerkat\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=1,\n",
        "    warmup_ratio=0.03,\n",
        "    learning_rate=2e-4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    max_grad_norm=0.3,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    peft_config=peft_cfg,\n",
        "    args=training_args,\n",
        "    max_seq_length=512,\n",
        "    packing=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21d5f93",
      "metadata": {
        "id": "b21d5f93"
      },
      "source": [
        "## 7) Train & Save the Fine-Tuned Model\n",
        "\n",
        "This will produce **Llama-2-7b-chat-meerkat** under `../../model/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e1bfa3",
      "metadata": {
        "id": "74e1bfa3",
        "outputId": "a7867e9e-0428-4301-f262-b620ffdc0f20"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='232' max='837964' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   232/837964 00:53 < 53:43:23, 4.33 it/s, Epoch 0.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.720400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.290700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.147700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.173400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.188300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.152600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.144000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.145900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Checkpoint destination directory ../../model/results-meerkat/checkpoint-25 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory ../../model/results-meerkat/checkpoint-50 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
            "Checkpoint destination directory ../../model/results-meerkat/checkpoint-75 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "\n",
        "# save under new name\n",
        "out_model = \"../../model/Llama-2-7b-chat-meerkat\"\n",
        "%time trainer.model.save_pretrained(out_model)\n",
        "trainer.tokenizer.save_pretrained(out_model)\n",
        "\n",
        "print(f\"✅ Fine-tuned model saved to {out_model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b446ad9a",
      "metadata": {
        "id": "b446ad9a"
      },
      "source": [
        "---\n",
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45478d8b",
      "metadata": {
        "id": "45478d8b"
      },
      "source": [
        "- https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/\n",
        "- https://llama.meta.com/llama2\n",
        "- https://huggingface.co/tasks/text-generation\n",
        "- https://arxiv.org/abs/2304.07327\n",
        "- https://huggingface.co/datasets/timdettmers/openassistant-guanaco\n",
        "- https://huggingface.co/docs/transformers/en/model_doc/llama2\n",
        "- https://huggingface.co/docs/peft/main/en/developer_guides/quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e7e9649",
      "metadata": {
        "tags": [],
        "id": "5e7e9649"
      },
      "source": [
        "## Licensing\n",
        "\n",
        "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90fee691288c4023a849609a71a963fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f17f35d5a5485b91ff5c7260131a5f",
              "IPY_MODEL_3f96458c41d647d1927861be69765c49",
              "IPY_MODEL_70933ead63e44f2bb4bd49a8ad2c5468"
            ],
            "layout": "IPY_MODEL_a9b45f78860f4c7ea58819468c63e3ab"
          }
        },
        "e0f17f35d5a5485b91ff5c7260131a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91121e22962240dca0e39159d0590c6c",
            "placeholder": "​",
            "style": "IPY_MODEL_13bcd583415f4e68a8366f7ecd805f3f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3f96458c41d647d1927861be69765c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee6a7900a7b4137849fa44d720dfb68",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f9afbfabf5d498180c17f29f51eeb9b",
            "value": 3
          }
        },
        "70933ead63e44f2bb4bd49a8ad2c5468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce4d59b2bbfb449abf1a240d6fc401f8",
            "placeholder": "​",
            "style": "IPY_MODEL_e00a9dbe93a9496b8785886f8abce2ef",
            "value": " 3/3 [00:05&lt;00:00,  1.73s/it]"
          }
        },
        "a9b45f78860f4c7ea58819468c63e3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91121e22962240dca0e39159d0590c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bcd583415f4e68a8366f7ecd805f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee6a7900a7b4137849fa44d720dfb68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9afbfabf5d498180c17f29f51eeb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce4d59b2bbfb449abf1a240d6fc401f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00a9dbe93a9496b8785886f8abce2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0116b1082014b22af343485726d8d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c089add359e746bb98fa31eb3cb138c9",
              "IPY_MODEL_27834aa314ed4339a2eb4a2cf0e8ffa2",
              "IPY_MODEL_15578feea14f4d40bc21f3967afae7c2"
            ],
            "layout": "IPY_MODEL_610f2f2501bb453d8b3dcdcb20ab5f44"
          }
        },
        "c089add359e746bb98fa31eb3cb138c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab85240109cd48be95bb73c1c7f3d80a",
            "placeholder": "​",
            "style": "IPY_MODEL_798caebbc7244c438f480fe6143054fd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "27834aa314ed4339a2eb4a2cf0e8ffa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3f500c2cd8452b8e896204b9dbda3d",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7bc89666b4c40c58697ec8386425913",
            "value": 3
          }
        },
        "15578feea14f4d40bc21f3967afae7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b0cd3463ca4ea9bf34e40c11843837",
            "placeholder": "​",
            "style": "IPY_MODEL_4f5181589fbf48c59d0774b8be671214",
            "value": " 3/3 [00:38&lt;00:00, 10.36s/it]"
          }
        },
        "610f2f2501bb453d8b3dcdcb20ab5f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab85240109cd48be95bb73c1c7f3d80a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798caebbc7244c438f480fe6143054fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c3f500c2cd8452b8e896204b9dbda3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bc89666b4c40c58697ec8386425913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25b0cd3463ca4ea9bf34e40c11843837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5181589fbf48c59d0774b8be671214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37f94484674e4319af71c9c90725f509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f91c8e4a87194f508eb205137ab9588e",
              "IPY_MODEL_aa6a2bc9e6e44c9cafb74388a3440449",
              "IPY_MODEL_d4e4c2fd026d4060a7185d1375c974ff"
            ],
            "layout": "IPY_MODEL_12156d3ad08e4adba39314e355fb16bc"
          }
        },
        "f91c8e4a87194f508eb205137ab9588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c85f9027e9d426998f28ac5ba0e79be",
            "placeholder": "​",
            "style": "IPY_MODEL_70710f1b8b2240bc95f49a45ce9b7b41",
            "value": "Generating train split: "
          }
        },
        "aa6a2bc9e6e44c9cafb74388a3440449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d21cac2eca64a728874c676889f4fdc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba6f827cc20a40a187a2a59ed760d593",
            "value": 1
          }
        },
        "d4e4c2fd026d4060a7185d1375c974ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828aa7a256ad471b8fd76c2ddf6abc91",
            "placeholder": "​",
            "style": "IPY_MODEL_9ab7e6b00fef4f46bcbb30b547dc7b18",
            "value": " 1778/0 [00:00&lt;00:00, 13577.21 examples/s]"
          }
        },
        "12156d3ad08e4adba39314e355fb16bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c85f9027e9d426998f28ac5ba0e79be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70710f1b8b2240bc95f49a45ce9b7b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d21cac2eca64a728874c676889f4fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ba6f827cc20a40a187a2a59ed760d593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "828aa7a256ad471b8fd76c2ddf6abc91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ab7e6b00fef4f46bcbb30b547dc7b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebfff18534ba4a14ae396820af4ff824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_312d649f9530440b81835bc4dd3a03f0",
              "IPY_MODEL_6338b9e90a41471d80e1098560479d4f",
              "IPY_MODEL_a466ef9111d54fe586b9983a020b65ad"
            ],
            "layout": "IPY_MODEL_b85049b021e540198c986f50eed5f54f"
          }
        },
        "312d649f9530440b81835bc4dd3a03f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e16e5d95514cacb284135e4956371e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee15a4ec0586406c96fcb9b1c1e8c5ef",
            "value": "Generating test split: "
          }
        },
        "6338b9e90a41471d80e1098560479d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06767481ea8342a896e53a9bb91d044d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47a394afd2284257b2f67448016f3d6b",
            "value": 1
          }
        },
        "a466ef9111d54fe586b9983a020b65ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86453d5d934e42f58e59c2f1a25cdb8c",
            "placeholder": "​",
            "style": "IPY_MODEL_37631c04429d489d87debd433505bae1",
            "value": " 189/0 [00:00&lt;00:00, 11248.29 examples/s]"
          }
        },
        "b85049b021e540198c986f50eed5f54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e16e5d95514cacb284135e4956371e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee15a4ec0586406c96fcb9b1c1e8c5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06767481ea8342a896e53a9bb91d044d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "47a394afd2284257b2f67448016f3d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86453d5d934e42f58e59c2f1a25cdb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37631c04429d489d87debd433505bae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1b1f09d656c4f2684a00261bd18efd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecbdd7505bc14f36a0492f1e33c6b986",
              "IPY_MODEL_89dda46f287247c9923fae73bad6a7e9",
              "IPY_MODEL_cbe4a6e006f146f89b3b2e6ab1593ef4"
            ],
            "layout": "IPY_MODEL_454250d70b804d1e814d636e82e65a27"
          }
        },
        "ecbdd7505bc14f36a0492f1e33c6b986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b1a6331223426d9ce3867462b2f2b6",
            "placeholder": "​",
            "style": "IPY_MODEL_7311901952ab4912b518aff660bfb84a",
            "value": "Map: 100%"
          }
        },
        "89dda46f287247c9923fae73bad6a7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91cf3936f8c41beaf6f40d9720b5232",
            "max": 1778,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc8af20c2d914c2f93e63971b2a59975",
            "value": 1778
          }
        },
        "cbe4a6e006f146f89b3b2e6ab1593ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec843417a6c24958b606323725f5d198",
            "placeholder": "​",
            "style": "IPY_MODEL_da478aa87ff2472c898ef4ba2f4c9c04",
            "value": " 1778/1778 [00:00&lt;00:00, 20472.32 examples/s]"
          }
        },
        "454250d70b804d1e814d636e82e65a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b1a6331223426d9ce3867462b2f2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7311901952ab4912b518aff660bfb84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a91cf3936f8c41beaf6f40d9720b5232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8af20c2d914c2f93e63971b2a59975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec843417a6c24958b606323725f5d198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da478aa87ff2472c898ef4ba2f4c9c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99f7c5d62554e449070c9d906f2db89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91c769571cc44985b50f53ea0af136c0",
              "IPY_MODEL_7aadcb3ffc004df485099c83014afeed",
              "IPY_MODEL_aab5785996684f669015d31b744c3cd3"
            ],
            "layout": "IPY_MODEL_5e9cb95201354753aac8cbec4a38eb70"
          }
        },
        "91c769571cc44985b50f53ea0af136c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b08a8c23fe4a06ab5ec4e126034909",
            "placeholder": "​",
            "style": "IPY_MODEL_54322985e0414444943b5700c0ed758f",
            "value": "Map: 100%"
          }
        },
        "7aadcb3ffc004df485099c83014afeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d95b9de0d9844799dbe8799790c5320",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a5f711f35ea4719828d9b7e5835a67c",
            "value": 189
          }
        },
        "aab5785996684f669015d31b744c3cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86543cd6b444f95a98b265c26cd27ed",
            "placeholder": "​",
            "style": "IPY_MODEL_196dc4cc30f848259cf5eceb82cab227",
            "value": " 189/189 [00:00&lt;00:00, 8645.41 examples/s]"
          }
        },
        "5e9cb95201354753aac8cbec4a38eb70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b08a8c23fe4a06ab5ec4e126034909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54322985e0414444943b5700c0ed758f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d95b9de0d9844799dbe8799790c5320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5f711f35ea4719828d9b7e5835a67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86543cd6b444f95a98b265c26cd27ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196dc4cc30f848259cf5eceb82cab227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9886f6c146a540d7acf147ed2f23cc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4863eddbad944b08753e0db7458efb8",
              "IPY_MODEL_1cbdd44882164abcbf079aeeb3793b41",
              "IPY_MODEL_6d46ef43c99e4f6186387a31623be70a"
            ],
            "layout": "IPY_MODEL_bfbc03b2dc7446ceb47e233fdc382a0d"
          }
        },
        "e4863eddbad944b08753e0db7458efb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810321cd62ca40ab84770d1ec7d717d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4155e6c0d8bf4ca28532c64359aa3e67",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "1cbdd44882164abcbf079aeeb3793b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc5006793234df393ee92cdb56be8e6",
            "max": 1778,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_583c99edb9864a9d9c4714d53d62d9b1",
            "value": 1778
          }
        },
        "6d46ef43c99e4f6186387a31623be70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c95708f5e5b4fb1a969dfcfa4b43461",
            "placeholder": "​",
            "style": "IPY_MODEL_a13a5b995631466c9987481967ca47dc",
            "value": " 1778/1778 [00:00&lt;00:00, 109526.97 examples/s]"
          }
        },
        "bfbc03b2dc7446ceb47e233fdc382a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "810321cd62ca40ab84770d1ec7d717d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4155e6c0d8bf4ca28532c64359aa3e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc5006793234df393ee92cdb56be8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583c99edb9864a9d9c4714d53d62d9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c95708f5e5b4fb1a969dfcfa4b43461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13a5b995631466c9987481967ca47dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee777dd578f64255885af27fb93dfaf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_330ab84138b34d229ac1af2c6156c5fa",
              "IPY_MODEL_97368aaf11ac4cb9841a74587217f330",
              "IPY_MODEL_024162c5b4c8417c817a3c73a3ffc37c"
            ],
            "layout": "IPY_MODEL_6d5bccd0a0c5465a9ce40fc3be30250a"
          }
        },
        "330ab84138b34d229ac1af2c6156c5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b551a09593f54128b05caa052a47e2a3",
            "placeholder": "​",
            "style": "IPY_MODEL_01abc413f8df4e779031e68d5c48da31",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "97368aaf11ac4cb9841a74587217f330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52165b2414c049d99d33c76b0dccdad1",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f70c1dd71614dd599dda8ed0c30f693",
            "value": 189
          }
        },
        "024162c5b4c8417c817a3c73a3ffc37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7944c84244941deac06a318df60a7ac",
            "placeholder": "​",
            "style": "IPY_MODEL_42e63149a2dd40bc93d020a328a1ad79",
            "value": " 189/189 [00:00&lt;00:00, 16160.88 examples/s]"
          }
        },
        "6d5bccd0a0c5465a9ce40fc3be30250a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b551a09593f54128b05caa052a47e2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01abc413f8df4e779031e68d5c48da31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52165b2414c049d99d33c76b0dccdad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f70c1dd71614dd599dda8ed0c30f693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7944c84244941deac06a318df60a7ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e63149a2dd40bc93d020a328a1ad79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a515158a79a44830ace5b3e78d862afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4047c35519b042b381fa39b538c15f5e",
              "IPY_MODEL_3e51927170e84e7a84d4562af40e9941",
              "IPY_MODEL_874beaf30f4547ac858769cafc7338f7"
            ],
            "layout": "IPY_MODEL_324cdb1a21d344438408087f44727cac"
          }
        },
        "4047c35519b042b381fa39b538c15f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fa4bebb0bcb4d5382671d59930a2452",
            "placeholder": "​",
            "style": "IPY_MODEL_780f00e43fd64ab39fcbe3e22008af41",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3e51927170e84e7a84d4562af40e9941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16f3138c916d46cd8212e7c96fd386aa",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cecfbfc9e354da4bfab8e1b636e593b",
            "value": 3
          }
        },
        "874beaf30f4547ac858769cafc7338f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4785afd7c4824ddf8e4700e2a6f17262",
            "placeholder": "​",
            "style": "IPY_MODEL_0e54bfe25d754dd3a29647ef5b80ed06",
            "value": " 3/3 [00:17&lt;00:00,  5.63s/it]"
          }
        },
        "324cdb1a21d344438408087f44727cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa4bebb0bcb4d5382671d59930a2452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780f00e43fd64ab39fcbe3e22008af41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16f3138c916d46cd8212e7c96fd386aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cecfbfc9e354da4bfab8e1b636e593b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4785afd7c4824ddf8e4700e2a6f17262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e54bfe25d754dd3a29647ef5b80ed06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}